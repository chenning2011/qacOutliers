<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Multivariate • qacOutliers</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Multivariate">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">qacOutliers</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/qacOutliers.html"><span class="fa fas fa-chalkboard-teacher"></span> Getting Started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fas fa-book"></span> Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes">
<li><a class="dropdown-item" href="../articles/Multivariate.html">Multivariate Outliers</a></li>
    <li><a class="dropdown-item" href="../articles/Univariate.html">Univariate Outliers</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-code-o"></span> Documentation</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="nav-link" href="../index.html"><span class="fa fa-home"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Multivariate</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/chenning2011/qacOutliers/blob/HEAD/vignettes/Multivariate.Rmd"><code>vignettes/Multivariate.Rmd</code></a></small>
      <div class="d-none name"><code>Multivariate.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/chenning2011/qacOutliers">qacOutliers</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="what-are-multivariate-outliers-how-do-you-detect-them">What are multivariate outliers? How do you detect them?<a class="anchor" aria-label="anchor" href="#what-are-multivariate-outliers-how-do-you-detect-them"></a>
</h2>
<p>A multivariate outlier is an outlier that can only be detected by
looking at two variables in combination. The graph below shows examples
of multivariate outliers. The data for this graph is taken from the <a href="https://rdrr.io/cran/carData/man/Salaries.html" class="external-link">Salaries</a>
dataset from the <a href="https://cran.r-project.org/web/packages/carData/index.html" class="external-link">carData</a>
package.</p>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-2-1.png" width="700"></p>
<p>All of the red dots are multivariate outliers. The point labelled 1
on the graph is a clear example of a multivariate outlier. This person
has their PhD for 22 years, a normal value for that variable, and makes
<code>$62,884</code>, which is also a normal value for salary. However,
when combining these two features, a person who has had 22 years since
their PhD and makes only <code>$62,884</code> is making much less than
other professors within their experience range.</p>
<p>The outliers in this graph were detected using the LoF method, and
more detail about that method can be provided below. This package
specifically focuses on four different methods for finding multivariate
outliers: kNN, LoF, mahalanobis distance, and iForest.</p>
</div>
<div class="section level2">
<h2 id="knn">kNN<a class="anchor" aria-label="anchor" href="#knn"></a>
</h2>
<p>kNN calculates the distances between a data point and its k-nearest
neighbors and assigns an outlier score based on that distance. The
principle that guides kNN is that outliers lay far away from their
neighbours, so each of the distances is interpreted within that context.
Because some variables in the data may have much larger ranges that
others (ex. a variable has a range from 1-10 and another has a range of
-10000 to 10000), the data is standardized before calculating the
distances.</p>
<p>Here is an example of the distances for the first 5 rows in <a href="https://chenning2011.github.io/qacOutliers/reference/mtcarsOutliers.html" class="external-link">mtcarsOutliers</a>,
a dataset included with this package.</p>
<pre><code><span><span class="co">#&gt;           [,1]     [,2]     [,3]     [,4]     [,5]</span></span>
<span><span class="co">#&gt; [1,] 1.5229770 2.102410 2.265502 2.651939 2.664224</span></span>
<span><span class="co">#&gt; [2,] 1.5031299 1.509144 1.522977 1.568453 1.608401</span></span>
<span><span class="co">#&gt; [3,] 1.2561178 1.503130 1.728826 1.817606 1.983652</span></span>
<span><span class="co">#&gt; [4,] 0.3490918 1.045627 1.163944 1.331333 1.351668</span></span>
<span><span class="co">#&gt; [5,] 4.7397611 5.019562 5.024754 5.026238 5.106755</span></span></code></pre>
<p>After each of these distances are calculated, the average for each
row is calculated. Here are the average scores for the 5 rows shown
above. This step is why it’s important to standardize the data before
finding the distances.</p>
<pre><code><span><span class="co">#&gt; [1] 2.241410 1.542421 1.657866 1.048333 4.983414</span></span></code></pre>
<p>In this function, the next step involves creating a threshold for
declaring a point an outlier. To calculate this threshold, the function
takes the average of each row (after that row’s average has been
calculated), and adds 2 times the standard deviation of each row to that
number. In this case, the threshold is the number below.</p>
<pre><code><span><span class="co">#&gt; [1] 5.657686</span></span></code></pre>
<p>Outliers are considered any points with a score above the calculated
threshold. In this case, the outliers are shown below.</p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 11 19</span></span>
<span><span class="co">#&gt; Outlier Score: 547.8248 393.1049</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl      disp        hp     drat    wt</span></span>
<span><span class="co">#&gt; Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440</span></span>
<span><span class="co">#&gt; Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615</span></span>
<span><span class="co">#&gt; Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570</span></span>
<span><span class="co">#&gt;                       qsec vs am      gear carb   scores</span></span>
<span><span class="co">#&gt; Merc 280C         18.90000  1  0 4.0000000    4 547.8248</span></span>
<span><span class="co">#&gt; Honda Civic       18.52000  1  1 4.0000000    2 393.1049</span></span>
<span><span class="co">#&gt; Merc 280          18.30000  1  0 4.0000000    4 318.1242</span></span>
<span><span class="co">#&gt; Hornet Sportabout 17.02000  0  0 3.0000000    2 189.8207</span></span>
<span><span class="co">#&gt; Maserati Bora     33.90273  0  1 0.9829575    8 117.9942</span></span></code></pre>
<div class="section level3">
<h3 id="customizing-the-k-parameter">Customizing the <code>k</code> parameter<a class="anchor" aria-label="anchor" href="#customizing-the-k-parameter"></a>
</h3>
<p>The value <code>k</code> tells the function how many points to
consider as neighbors when identifying distances between each of the
points. The default value, 5, finds the distance between each point the
5 points that are closest to that point. The choice of <code>k</code>
significantly impacts the results, and smaller values are generally more
sensitive to outliers. You can supply your own value of <code>k</code>,
which may change the results of the function.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"kNN"</span>, k <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 11 19</span></span>
<span><span class="co">#&gt; Outlier Score: 568.7642 441.0597</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl      disp        hp     drat    wt</span></span>
<span><span class="co">#&gt; Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440</span></span>
<span><span class="co">#&gt; Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615</span></span>
<span><span class="co">#&gt; Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570</span></span>
<span><span class="co">#&gt;                       qsec vs am      gear carb   scores</span></span>
<span><span class="co">#&gt; Merc 280C         18.90000  1  0 4.0000000    4 568.7642</span></span>
<span><span class="co">#&gt; Honda Civic       18.52000  1  1 4.0000000    2 441.0597</span></span>
<span><span class="co">#&gt; Merc 280          18.30000  1  0 4.0000000    4 330.3313</span></span>
<span><span class="co">#&gt; Hornet Sportabout 17.02000  0  0 3.0000000    2 230.4534</span></span>
<span><span class="co">#&gt; Maserati Bora     33.90273  0  1 0.9829575    8 145.8174</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output">Example Output<a class="anchor" aria-label="anchor" href="#example-output"></a>
</h3>
<p>When using the kNN method with the default <code>k=5</code>, the
function returns:</p>
<ul>
<li>Method: “kNN”, indicating the method used.</li>
<li>Dataset: The dataset name.</li>
<li>Variables: The numeric columns considered for outlier
detection.</li>
<li>Row: Indices of rows identified as outliers.</li>
<li>Score: Average kNN distance scores of detected outliers.</li>
<li>Message: A summary message indicating whether outliers were
detected.</li>
<li>k: The number of nearest neighbors considered.</li>
<li>Data: Displays the five highest outliers in the data used.</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"kNN"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 11 19</span></span>
<span><span class="co">#&gt; Outlier Score: 547.8248 393.1049</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl      disp        hp     drat    wt</span></span>
<span><span class="co">#&gt; Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440</span></span>
<span><span class="co">#&gt; Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615</span></span>
<span><span class="co">#&gt; Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570</span></span>
<span><span class="co">#&gt;                       qsec vs am      gear carb   scores</span></span>
<span><span class="co">#&gt; Merc 280C         18.90000  1  0 4.0000000    4 547.8248</span></span>
<span><span class="co">#&gt; Honda Civic       18.52000  1  1 4.0000000    2 393.1049</span></span>
<span><span class="co">#&gt; Merc 280          18.30000  1  0 4.0000000    4 318.1242</span></span>
<span><span class="co">#&gt; Hornet Sportabout 17.02000  0  0 3.0000000    2 189.8207</span></span>
<span><span class="co">#&gt; Maserati Bora     33.90273  0  1 0.9829575    8 117.9942</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: grid</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Numeric Data Only: The kNN method requires numeric variables.
Non-numeric columns are automatically excluded.</p></li>
<li><p>Robustness: kNN does not assume a specific distribution of data,
so it is robust to non-normality, making it a better tool to handle
non-normal data than other outlier detection methods.</p></li>
</ol>
<p>To learn more about kNN and how it’s used in multivariate outlier
detection, visit these resources:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/k-nearest-neighbours/#" class="external-link">GeeksforGeeks.com</a></li>
<li><a href="https://dualitytech.com/blog/anomaly-detection-k-nearest-neighbors/" class="external-link">Dualitytech.com</a></li>
<li><a href="https://www.youtube.com/watch?v=HVXime0nQeI" class="external-link">StatQuest</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="local-outlier-factor-lof">Local outlier factor (LoF)<a class="anchor" aria-label="anchor" href="#local-outlier-factor-lof"></a>
</h2>
<p>The Local Outlier Factor (LoF) method detects anomalies by comparing
the density of data points in their local neighborhood. Points with
significantly lower density than their neighbors are flagged as
potential outliers. The dbscan package is used for this implementation,
which calculates LoF scores for each data point. Scores above a certain
threshold (typically &gt; 1) are indicative of stronger outliers.</p>
<p>LoF is particularly useful for datasets with clusters of varying
density, as it considers the local density when assessing outlierness.
It supports both numeric and categorical variables, using Gower distance
for mixed data types.</p>
<p>Here is an example of the scores using the <a href="https://chenning2011.github.io/qacOutliers/reference/mtcarsOutliers.html" class="external-link">mtcarsOutliers</a>
dataset included with this package.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/mhahsler/dbscan" class="external-link">dbscan</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dbscan'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     as.dendrogram</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">mtcarsOutliers</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="va">data_scaled</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">lof_scores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dbscan/man/lof.html" class="external-link">lof</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">data_scaled</span><span class="op">)</span>, minPts <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">lof_scores</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.1995026 1.0700106 0.9325731 1.4719657 3.3479437</span></span></code></pre></div>
<div class="section level3">
<h3 id="customizing-the-minpts-parameter">Customizing the <code>minPts</code> Parameter<a class="anchor" aria-label="anchor" href="#customizing-the-minpts-parameter"></a>
</h3>
<p>The LoF method allows customization of the <code>minPts</code>
parameter, which is the minimum number of points in the local
neighborhood. Larger values result in broader neighborhoods and may
reduce sensitivity to smaller clusters. Default is 5.</p>
<p>You can adjust these parameters to suit your dataset. Here’s an
example:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"LoF"</span>, minPts <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: LoF</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 7 9 10 11 12 20 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 2.28365 2.719583 2.560179 1.530304 1.563598 1.804971 1.567824 2.950466 1.574599</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : minPts = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl  disp      hp     drat        wt     qsec</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273</span></span>
<span><span class="co">#&gt; Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000</span></span>
<span><span class="co">#&gt; Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000</span></span>
<span><span class="co">#&gt; Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000</span></span>
<span><span class="co">#&gt;                          vs am      gear carb   scores</span></span>
<span><span class="co">#&gt; Maserati Bora      0.000000  1 0.9829575    8 2.950466</span></span>
<span><span class="co">#&gt; Duster 360         0.000000  0 3.0000000    4 2.719583</span></span>
<span><span class="co">#&gt; Merc 230          -8.556805  0 4.0000000    2 2.560179</span></span>
<span><span class="co">#&gt; Hornet Sportabout  0.000000  0 3.0000000    2 2.283650</span></span>
<span><span class="co">#&gt; Merc 450SE         0.000000  0 3.0000000    3 1.804971</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-1">Example Output<a class="anchor" aria-label="anchor" href="#example-output-1"></a>
</h3>
<p>When using the LoF method with the default minPts = 5, the function
returns:</p>
<ul>
<li>Method: “LoF”, indicating the method used.</li>
<li>Dataset: The dataset name.</li>
<li>Variables: The columns considered in the analysis.</li>
<li>Row: Indices of rows identified as outliers.</li>
<li>Score: LoF scores for each detected outlier.</li>
<li>Message: A summary message indicating whether outliers were
detected.</li>
<li>minPts: The parameter value used for the local neighborhood.</li>
<li>Data: Displays the five highest outliers in the data used.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"LoF"</span><span class="op">)</span></span>
<span><span class="va">result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: LoF</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 7 9 10 11 12 20 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 2.28365 2.719583 2.560179 1.530304 1.563598 1.804971 1.567824 2.950466 1.574599</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : minPts = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl  disp      hp     drat        wt     qsec</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273</span></span>
<span><span class="co">#&gt; Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000</span></span>
<span><span class="co">#&gt; Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000</span></span>
<span><span class="co">#&gt; Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000</span></span>
<span><span class="co">#&gt;                          vs am      gear carb   scores</span></span>
<span><span class="co">#&gt; Maserati Bora      0.000000  1 0.9829575    8 2.950466</span></span>
<span><span class="co">#&gt; Duster 360         0.000000  0 3.0000000    4 2.719583</span></span>
<span><span class="co">#&gt; Merc 230          -8.556805  0 4.0000000    2 2.560179</span></span>
<span><span class="co">#&gt; Hornet Sportabout  0.000000  0 3.0000000    2 2.283650</span></span>
<span><span class="co">#&gt; Merc 450SE         0.000000  0 3.0000000    3 1.804971</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-13-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-1">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-1"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Sensitivity to minPts: The choice of minPts significantly
influences results. A value too small might result in over-sensitivity,
while a value too large might overlook smaller clusters of
anomalies.</p></li>
<li><p>Mixed Data Types: If the dataset contains categorical variables,
the method automatically switches to Gower distance for calculating
pairwise dissimilarities. Ensure the data is properly encoded.</p></li>
<li><p>Interpreting LoF Scores: Scores greater than 1.5 typically
indicate potential outliers. Adjust the threshold based on the
characteristics of your dataset.</p></li>
</ol>
<p>To learn more about Mahalanobis distance and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li><a href="https://towardsdatascience.com/local-outlier-factor-lof-algorithm-for-outlier-identification-8efb887d9843" class="external-link">Medium.com</a></li>
<li><a href="https://scikit-learn.org/dev/modules/generated/sklearn.cluster.DBSCAN.html" class="external-link">DBSCAN
Documentation</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="mahalanobis">Mahalanobis<a class="anchor" aria-label="anchor" href="#mahalanobis"></a>
</h2>
<p>The Mahalanobis distance measures the distance of a point from the
center of a multivariate distribution while accounting for the
correlation between variables. This method identifies outliers by
calculating how far each point is from the data’s multivariate mean,
considering the covariance matrix of the data. This approach is
particularly useful when variables are highly correlated or have
different scales.</p>
<p>Before using the Mahalanobis distance, the function automatically
selects numeric columns from the dataset. Non-numeric variables are
excluded, ensuring compatibility with the method. The distances are then
calculated using the <a href="https://www.rdocumentation.org/packages/Routliers/versions/0.0.0.3/topics/outliers_mahalanobis" class="external-link">outliers_mahalanobis</a>
function from the <a href="https://cran.r-project.org/web/packages/Routliers/index.html" class="external-link">Routliers</a>
package.</p>
<p>Here is an example of calculating Mahalanobis distances for the <a href="https://chenning2011.github.io/qacOutliers/reference/mtcarsOutliers.html" class="external-link">mtcarsOutliers</a>
dataset included with this package:</p>
<pre><code><span><span class="co">#&gt;         Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive </span></span>
<span><span class="co">#&gt;          7.217210          3.682371          5.829785          1.981340 </span></span>
<span><span class="co">#&gt; Hornet Sportabout </span></span>
<span><span class="co">#&gt;         25.022031</span></span></code></pre>
<p>The outliers are identified by the function and their indices are
returned:</p>
<pre><code><span><span class="co">#&gt; Hornet Sportabout        Duster 360          Merc 230          Merc 280 </span></span>
<span><span class="co">#&gt;                 5                 7                 9                10 </span></span>
<span><span class="co">#&gt;    Toyota Corolla     Maserati Bora        Volvo 142E </span></span>
<span><span class="co">#&gt;                20                31                32</span></span></code></pre>
<p>Outliers are identified by comparing the Mahalanobis distance of each
point to a threshold derived from the chi-squared distribution. Points
with distances greater than the critical value at a specified
significance level (<code>alpha</code>) are flagged as outliers. The
default <code>alpha</code> is 0.05, which corresponds to a 95%
confidence level. You can customize this value to adjust the sensitivity
of the detection.</p>
<p>Here is the threshold for the dataset using the default
<code>alpha = 0.05</code>:</p>
<pre><code><span><span class="co">#&gt; [1] 18.30704</span></span></code></pre>
<div class="section level3">
<h3 id="customizing-the-alpha-parameter">Customizing the <code>alpha</code> parameter<a class="anchor" aria-label="anchor" href="#customizing-the-alpha-parameter"></a>
</h3>
<p>The <code>alpha</code> parameter in outliers_mahalanobis determines
the significance level for outlier detection. Lower values (e.g.,
<code>alpha = 0.01</code>) result in stricter thresholds, identifying
fewer points as outliers. You can modify <code>alpha</code> as
follows:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"mahalanobis"</span>, alpha <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: mahalanobis</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 7 9 12 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 25.11784 29.58581 27.30969 26.99406 27.95683 25.39721</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : alpha = 0.01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                    mpg cyl  disp  hp     drat        wt     qsec        vs am</span></span>
<span><span class="co">#&gt; Duster 360    14.30000   8 360.0 245 18.14468  3.570000 15.84000  0.000000  0</span></span>
<span><span class="co">#&gt; Maserati Bora 15.00000   8 301.0 335  3.54000  3.570000 33.90273  0.000000  1</span></span>
<span><span class="co">#&gt; Merc 230      22.80000   4 140.8  95  3.92000 -4.541341 22.90000 -8.556805  0</span></span>
<span><span class="co">#&gt; Merc 450SE    54.17757   8 275.8 180  3.07000  4.070000 17.40000  0.000000  0</span></span>
<span><span class="co">#&gt; Volvo 142E    21.40000   4 121.0 109  4.11000  2.780000 18.60000  1.000000  1</span></span>
<span><span class="co">#&gt;                    gear      carb   scores</span></span>
<span><span class="co">#&gt; Duster 360    3.0000000   4.00000 29.58581</span></span>
<span><span class="co">#&gt; Maserati Bora 0.9829575   8.00000 27.95683</span></span>
<span><span class="co">#&gt; Merc 230      4.0000000   2.00000 27.30969</span></span>
<span><span class="co">#&gt; Merc 450SE    3.0000000   3.00000 26.99406</span></span>
<span><span class="co">#&gt; Volvo 142E    4.0000000 -12.91235 25.39721</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-2">Example Output<a class="anchor" aria-label="anchor" href="#example-output-2"></a>
</h3>
<p>When using the Mahalanobis method with the default
<code>alpha = 0.05</code>, the function returns:</p>
<ul>
<li>Method: “mahalanobis”, indicating the method used.</li>
<li>Dataset: The dataset name.</li>
<li>Variables: The numeric columns considered.</li>
<li>Row: Indices of rows identified as outliers.</li>
<li>Score: Mahalanobis distance scores of detected outliers.</li>
<li>Message: A summary message indicating whether outliers were
detected.</li>
<li>Alpha: The significance level used.</li>
<li>Data: Displays the five highest outliers in the data used.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"mahalanobis"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: mahalanobis</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 7 9 10 12 20 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 25.11784 29.58581 27.30969 19.22256 26.99406 21.46034 27.95683 25.39721</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : alpha = 0.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                    mpg cyl  disp  hp     drat        wt     qsec        vs am</span></span>
<span><span class="co">#&gt; Duster 360    14.30000   8 360.0 245 18.14468  3.570000 15.84000  0.000000  0</span></span>
<span><span class="co">#&gt; Maserati Bora 15.00000   8 301.0 335  3.54000  3.570000 33.90273  0.000000  1</span></span>
<span><span class="co">#&gt; Merc 230      22.80000   4 140.8  95  3.92000 -4.541341 22.90000 -8.556805  0</span></span>
<span><span class="co">#&gt; Merc 450SE    54.17757   8 275.8 180  3.07000  4.070000 17.40000  0.000000  0</span></span>
<span><span class="co">#&gt; Volvo 142E    21.40000   4 121.0 109  4.11000  2.780000 18.60000  1.000000  1</span></span>
<span><span class="co">#&gt;                    gear      carb   scores</span></span>
<span><span class="co">#&gt; Duster 360    3.0000000   4.00000 29.58581</span></span>
<span><span class="co">#&gt; Maserati Bora 0.9829575   8.00000 27.95683</span></span>
<span><span class="co">#&gt; Merc 230      4.0000000   2.00000 27.30969</span></span>
<span><span class="co">#&gt; Merc 450SE    3.0000000   3.00000 26.99406</span></span>
<span><span class="co">#&gt; Volvo 142E    4.0000000 -12.91235 25.39721</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-19-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-2">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-2"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Numeric Data Only: The Mahalanobis method requires numeric
variables. Non-numeric columns are automatically excluded.</p></li>
<li><p>Multivariate Normality: This method assumes the data follows a
multivariate normal distribution. Deviations from normality or the
presence of extreme outliers may affect the results.</p></li>
</ol>
<p>To learn more about Mahalanobis distance and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li><a href="https://www.statisticshowto.com/mahalanobis-distance/" class="external-link">Statisticshowto.com</a></li>
<li><a href="https://builtin.com/data-science/mahalanobis-distance" class="external-link">Builtin.com</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="iforest">iForest<a class="anchor" aria-label="anchor" href="#iforest"></a>
</h2>
<p>Isolation Forest (iForest) is an unsupervised machine learning
algorithm designed to detect anomalies in data is implemented using the
<code>isotree</code> package. It works by creating random partitions of
the data and measuring how quickly each point can be isolated. Points
that are isolated faster (using fewer splits) are more likely to be
outliers.</p>
<p>The iForest algorithm is particularly well-suited for handling
high-dimensional data and works with both quantitative and categorical
variables. It is robust to noise and scales efficiently for large
datasets.</p>
<p>Here is an example of the scores using the <a href="https://chenning2011.github.io/qacOutliers/reference/mtcarsOutliers.html" class="external-link">mtcarsOutliers</a>
dataset included with this package.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/david-cortes/isotree" class="external-link">isotree</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: package 'isotree' was built under R version 4.4.2</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">mtcarsOutliers</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="va">isolation_forest_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/isotree/man/isolation.forest.html" class="external-link">isolation.forest</a></span><span class="op">(</span><span class="va">data</span>, ntrees <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">data</span><span class="op">$</span><span class="va">iso_score</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">isolation_forest_model</span>, <span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">iso_score</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.4249880 0.3782837 0.3807095 0.3695911 0.5066493</span></span></code></pre></div>
<div class="section level3">
<h3 id="customizing-parameters">Customizing Parameters<a class="anchor" aria-label="anchor" href="#customizing-parameters"></a>
</h3>
<p>The iForest method allows customization of two main parameters:</p>
<p>ntrees: The number of trees in the isolation forest. A higher value
increases precision but also computation time. Default is 100.</p>
<p>n: The number of points to return as outliers. Default is 5.</p>
<p>Here’s an example of how you can modify these parameters:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"iForest"</span>, ntrees <span class="op">=</span> <span class="fl">200</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: iForest</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 7 9 10 12 19 20 29 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 0.5932919 0.5876694 0.5168765 0.5038969 0.4751465 0.4591736 0.4582887 0.4562152 0.4447788 0.4408235</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : ntrees = 200</span></span>
<span><span class="co">#&gt; Option 2 : n = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                        mpg       cyl  disp        hp     drat        wt</span></span>
<span><span class="co">#&gt; Maserati Bora     15.00000  8.000000 301.0  335.0000 3.540000  3.570000</span></span>
<span><span class="co">#&gt; Merc 230          22.80000  4.000000 140.8   95.0000 3.920000 -4.541341</span></span>
<span><span class="co">#&gt; Toyota Corolla    33.90000  4.000000  71.1   65.0000 4.220000  1.835000</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.70000 -4.137792 360.0  446.9140 3.150000  3.440000</span></span>
<span><span class="co">#&gt; Merc 280          44.30673  6.000000 167.6 -238.7728 4.560312  3.440000</span></span>
<span><span class="co">#&gt;                       qsec        vs am      gear      carb    scores</span></span>
<span><span class="co">#&gt; Maserati Bora     33.90273  0.000000  1 0.9829575  8.000000 0.5932919</span></span>
<span><span class="co">#&gt; Merc 230          22.90000 -8.556805  0 4.0000000  2.000000 0.5876694</span></span>
<span><span class="co">#&gt; Toyota Corolla    19.90000  6.993352  1 4.0000000 -7.344032 0.5168765</span></span>
<span><span class="co">#&gt; Hornet Sportabout 17.02000  0.000000  0 3.0000000  2.000000 0.5038969</span></span>
<span><span class="co">#&gt; Merc 280          18.30000  1.000000  0 4.0000000  4.000000 0.4751465</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-3">Example Output<a class="anchor" aria-label="anchor" href="#example-output-3"></a>
</h3>
<p>When using the iForest method with the default
<code>ntrees = 100</code> and <code>n = 5</code> the function
returns:</p>
<ul>
<li>Method: “iForest”, indicating the method used.</li>
<li>Dataset: The dataset name.</li>
<li>Variables: The numeric columns considered.</li>
<li>Row: Indices of rows identified as outliers.</li>
<li>Score: Isolation scores for each detected outlier.</li>
<li>Message: A summary message indicating whether outliers were
detected.</li>
<li>ntrees: The number of trees in the isolation forest</li>
<li>n: The number of points to return as outliers</li>
<li>Data: Displays the five highest outliers in the data used.</li>
</ul>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"iForest"</span><span class="op">)</span></span>
<span><span class="va">result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: iForest</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores</span></span>
<span><span class="co">#&gt; Row: 5 9 20 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 0.5912855 0.5673572 0.5386362 0.4858491 0.4728747</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : ntrees = 100</span></span>
<span><span class="co">#&gt; Option 2 : n = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Highest Outliers of Data Used:</span></span>
<span><span class="co">#&gt;                    mpg       cyl  disp      hp drat        wt     qsec</span></span>
<span><span class="co">#&gt; Merc 230          22.8  4.000000 140.8  95.000 3.92 -4.541341 22.90000</span></span>
<span><span class="co">#&gt; Maserati Bora     15.0  8.000000 301.0 335.000 3.54  3.570000 33.90273</span></span>
<span><span class="co">#&gt; Toyota Corolla    33.9  4.000000  71.1  65.000 4.22  1.835000 19.90000</span></span>
<span><span class="co">#&gt; Hornet Sportabout 18.7 -4.137792 360.0 446.914 3.15  3.440000 17.02000</span></span>
<span><span class="co">#&gt; Volvo 142E        21.4  4.000000 121.0 109.000 4.11  2.780000 18.60000</span></span>
<span><span class="co">#&gt;                          vs am      gear       carb    scores</span></span>
<span><span class="co">#&gt; Merc 230          -8.556805  0 4.0000000   2.000000 0.5912855</span></span>
<span><span class="co">#&gt; Maserati Bora      0.000000  1 0.9829575   8.000000 0.5673572</span></span>
<span><span class="co">#&gt; Toyota Corolla     6.993352  1 4.0000000  -7.344032 0.5386362</span></span>
<span><span class="co">#&gt; Hornet Sportabout  0.000000  0 3.0000000   2.000000 0.4858491</span></span>
<span><span class="co">#&gt; Volvo 142E         1.000000  1 4.0000000 -12.912355 0.4728747</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-3">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-3"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Scalability: Isolation Forest is designed to handle large
datasets efficiently, making it suitable for high-dimensional data.
However, performance may depend on the ntrees parameter, as higher
values can increase computation time.</p></li>
<li><p>No Assumptions on Data Distribution: Unlike some statistical
methods, iForest does not assume a specific data distribution. This
makes it robust for detecting outliers in diverse datasets.</p></li>
<li><p>Handles Mixed Data Types: iForest can process both numeric and
categorical variables. However, ensure your data is properly encoded or
formatted as required by the isotree package.</p></li>
<li><p>Interpretation of Scores: Higher isolation scores indicate
stronger anomalies. You may need to determine an appropriate threshold
for your dataset when interpreting the results.</p></li>
</ol>
<p>To learn more about Isolation Forest and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li><a href="https://medium.com/@limyenwee_19946/unsupervised-outlier-detection-with-isolation-forest-eab398c593b2" class="external-link">Medium.com</a></li>
<li><a href="https://www.youtube.com/watch?v=O9VvmWj-JAk" class="external-link">Andy McDonald
on YouTube</a></li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Caleb Henning, Larissa Xu, Angelica Crown, Ernie Little, Braeden Falzarano, Ral Reyes, Tegh Singh.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
