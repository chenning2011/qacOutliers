<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Multivariate • qacOutliers</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Multivariate">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">qacOutliers</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/qacOutliers.html"><span class="fa fas fa-chalkboard-teacher"></span> Getting Started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fas fa-book"></span> Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes">
<li><a class="dropdown-item" href="../articles/Univariate.html">Univariate Outliers</a></li>
    <li><a class="dropdown-item" href="../articles/Multivariate.html">Multivariate Outliers</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-code-o"></span> Documentation</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="nav-link" href="../index.html"><span class="fa fa-home"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Multivariate</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/chenning2011/qacOutliers/blob/HEAD/vignettes/Multivariate.Rmd"><code>vignettes/Multivariate.Rmd</code></a></small>
      <div class="d-none name"><code>Multivariate.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/chenning2011/qacOutliers">qacOutliers</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="what-are-multivariate-outliers-how-do-you-detect-them">What are multivariate outliers? How do you detect them?<a class="anchor" aria-label="anchor" href="#what-are-multivariate-outliers-how-do-you-detect-them"></a>
</h2>
<p>A multivariate outlier is an outlier that can only be detected by
looking at two or more variables in combination. The graph below shows
examples of multivariate outliers using the <code>iris</code> dataset
included with base R.</p>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-2-1.png" width="700"></p>
<p>The red point labelled <code>1</code> on the graph is a clear example
of a multivariate outlier. This flower has a Sepal Length of 4.9 inches,
and a Petal Width of 1.7 inches, both of which seem like normal values
for Sepal Length and Petal Width. However, flowers with a Sepal Length
of around 5 inches normally have much smaller Petal Widths, as shown on
the graph above. While there are other outliers in this dataset, only
this outlier has been colored red to draw extra attention to it.</p>
<p>The outlier in this graph was detected using the LoF method, and more
detail about that method can be provided below. This package
specifically focuses on four different methods for finding multivariate
outliers: kNN, LoF, mahalanobis distance, and iForest.</p>
</div>
<div class="section level2">
<h2 id="knn">kNN<a class="anchor" aria-label="anchor" href="#knn"></a>
</h2>
<p>kNN calculates the distances between a data point and its k-nearest
neighbors and assigns an outlier score based on that distance. The
principle that guides kNN is that outliers lay far away from their
neighbours, so each of the distances is interpreted within that context.
Because some variables in the data may have much larger ranges that
others (ex. a variable has a range from 1-10 and another has a range of
-10000 to 10000), the data is standardized before calculating the
distances.</p>
<p>After each of these distances is calculated, the mean for each row is
calculated. The next step involves creating a threshold for declaring a
point an outlier. To calculate this threshold, the function takes the
mean of each row (after that row’s mean has been calculated), and adds 2
times the standard deviation of each row to that number. Outliers are
considered any points with a score above the calculated threshold.
Because this method relies on numeric variables, all categorical
variables are removed.</p>
<p>Here is an example of the final output from the
<code>multiOutliers</code> function using the kNN method.</p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg disp hp drat wt qsec</span></span>
<span><span class="co">#&gt; Row: 1 3 16</span></span>
<span><span class="co">#&gt; Outlier Score: 389.3906 557.6478 403.178</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                      mpg      disp        hp drat       wt  qsec   scores</span></span>
<span><span class="co">#&gt; Datsun 710          22.8 -468.2171   93.0000 3.85 13.16772 18.61 557.6478</span></span>
<span><span class="co">#&gt; Lincoln Continental 10.4  460.0000 -232.3693 3.00  5.42400 17.82 403.1780</span></span>
<span><span class="co">#&gt; Mazda RX4           21.0  782.5020  110.0000 3.90  2.62000 16.46 389.3906</span></span>
<span><span class="co">#&gt; Honda Civic         30.4   75.7000 -240.5539 4.93  1.61500 18.52 312.8635</span></span>
<span><span class="co">#&gt; Maserati Bora       15.0  301.0000  335.0000 3.54  3.57000 14.60 122.3927</span></span></code></pre>
<div class="section level3">
<h3 id="customizing-the-k-parameter">Customizing the <code>k</code> parameter<a class="anchor" aria-label="anchor" href="#customizing-the-k-parameter"></a>
</h3>
<p>The value <code>k</code> tells the function how many points to
consider as neighbors when identifying distances between each of the
points. The default value, 5, finds the distance between each point the
5 points that are closest to that point. The choice of <code>k</code>
significantly impacts the results, and smaller values are generally more
sensitive to outliers. You can supply your own value of <code>k</code>,
which may change the results of the function.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"knn"</span>, k <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg disp hp drat wt qsec</span></span>
<span><span class="co">#&gt; Row: 1 3 16</span></span>
<span><span class="co">#&gt; Outlier Score: 427.538 581.0315 416.7779</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                      mpg      disp        hp drat       wt  qsec   scores</span></span>
<span><span class="co">#&gt; Datsun 710          22.8 -468.2171   93.0000 3.85 13.16772 18.61 581.0315</span></span>
<span><span class="co">#&gt; Mazda RX4           21.0  782.5020  110.0000 3.90  2.62000 16.46 427.5380</span></span>
<span><span class="co">#&gt; Lincoln Continental 10.4  460.0000 -232.3693 3.00  5.42400 17.82 416.7779</span></span>
<span><span class="co">#&gt; Honda Civic         30.4   75.7000 -240.5539 4.93  1.61500 18.52 331.5026</span></span>
<span><span class="co">#&gt; Maserati Bora       15.0  301.0000  335.0000 3.54  3.57000 14.60 148.4708</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output">Example Output<a class="anchor" aria-label="anchor" href="#example-output"></a>
</h3>
<p>When using the kNN method with the default <code>k=5</code>, the
function returns:</p>
<ul>
<li>
<code>Method</code>: “kNN”, indicating the method used.</li>
<li>
<code>Dataset</code>: The dataset name.</li>
<li>
<code>Variables</code>: The numeric columns considered for outlier
detection.</li>
<li>
<code>Row</code>: Indices of rows identified as outliers.</li>
<li>
<code>Score</code>: Mean kNN distance scores of detected
outliers.</li>
<li>
<code>Message</code>: A summary message indicating whether outliers
were detected.</li>
<li>
<code>k</code>: The number of nearest neighbors considered.</li>
<li>
<code>Data</code>: Displays the five highest outliers in the data
used.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"knn"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: kNN</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg disp hp drat wt qsec</span></span>
<span><span class="co">#&gt; Row: 1 3 16</span></span>
<span><span class="co">#&gt; Outlier Score: 389.3906 557.6478 403.178</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : k = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                      mpg      disp        hp drat       wt  qsec   scores</span></span>
<span><span class="co">#&gt; Datsun 710          22.8 -468.2171   93.0000 3.85 13.16772 18.61 557.6478</span></span>
<span><span class="co">#&gt; Lincoln Continental 10.4  460.0000 -232.3693 3.00  5.42400 17.82 403.1780</span></span>
<span><span class="co">#&gt; Mazda RX4           21.0  782.5020  110.0000 3.90  2.62000 16.46 389.3906</span></span>
<span><span class="co">#&gt; Honda Civic         30.4   75.7000 -240.5539 4.93  1.61500 18.52 312.8635</span></span>
<span><span class="co">#&gt; Maserati Bora       15.0  301.0000  335.0000 3.54  3.57000 14.60 122.3927</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Numeric Data Only: The kNN method requires numeric variables.
Non-numeric columns are automatically excluded.</p></li>
<li><p>Robustness: kNN does not assume a specific distribution of data,
so it is robust to non-normality, making it a better tool to handle
non-normal data than other outlier detection methods.</p></li>
</ol>
<p>To learn more about kNN and how it’s used in multivariate outlier
detection, visit these resources:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/k-nearest-neighbours/#" class="external-link">GeeksforGeeks.com</a></li>
<li><a href="https://dualitytech.com/blog/anomaly-detection-k-nearest-neighbors/" class="external-link">Dualitytech.com</a></li>
<li><a href="https://www.youtube.com/watch?v=HVXime0nQeI" class="external-link">StatQuest</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="local-outlier-factor-lof">Local outlier factor (LoF)<a class="anchor" aria-label="anchor" href="#local-outlier-factor-lof"></a>
</h2>
<p>The Local Outlier Factor (LoF) method detects anomalies by comparing
the density of data points in their local neighborhood. Points with
significantly lower density than their neighbors are flagged as
potential outliers. The <a href="https://cran.r-project.org/web/packages/dbscan/readme/README.html" class="external-link">dbscan</a>
package is used for this implementation, which calculates LoF scores for
each data point. Scores above a certain threshold (typically &gt; 1) are
indicative of stronger outliers.</p>
<p>LoF is particularly useful for datasets with clusters of varying
density, as it considers the local density when assessing outlier
scores. It supports both numeric and categorical variables, using Gower
distance for mixed data types. This LoF method uses the <a href="https://cran.r-project.org/web/packages/cluster/index.html" class="external-link">cluster</a>
package’s daisy (Dissimilarity Matrix Calculation) function to calculate
the Gower distance when necessary.</p>
<div class="section level3">
<h3 id="customizing-the-minpts-parameter">Customizing the <code>minPts</code> Parameter<a class="anchor" aria-label="anchor" href="#customizing-the-minpts-parameter"></a>
</h3>
<p>The LoF method allows customization of the <code>minPts</code>
parameter, which is the minimum number of points in the local
neighborhood. Larger values result in broader neighborhoods and may
reduce sensitivity to smaller clusters. <code>minPts</code> defaults to
5 if not specified.</p>
<p>You can adjust these parameters to suit your dataset. Here’s an
example:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"lof"</span>, minPts <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: LoF</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Row: 1 2 3 4 6 7 10 11 15 16 17 20 24 26 27 29 30 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 1.234384 1.109279 1.052523 1.434807 1.590262 1.031151 1.000967 1.002118 1.004441 1.2053 1.015402 1.013044 1.088952 1.002205 1.043699 1.419062 1.752452 1.94842 1.017775</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : minPts = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                     mpg cyl disp  hp      drat    wt  qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Maserati Bora  15.00000   8  301 335  3.540000 3.570 14.60  0  1    5    8</span></span>
<span><span class="co">#&gt; Ferrari Dino   19.70000   6  145 175 -5.146597 2.770 15.50  0  1    5    6</span></span>
<span><span class="co">#&gt; Valiant        18.10000   6  225 105  2.760000 3.460 20.22  1  0    3    1</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 54.27716   6  258 110  3.080000 3.215 19.44  1  0    3    1</span></span>
<span><span class="co">#&gt; Ford Pantera L 15.80000   8  351 264  4.220000 3.170 14.50  0  1    5    4</span></span>
<span><span class="co">#&gt;                  scores</span></span>
<span><span class="co">#&gt; Maserati Bora  1.948420</span></span>
<span><span class="co">#&gt; Ferrari Dino   1.752452</span></span>
<span><span class="co">#&gt; Valiant        1.590262</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 1.434807</span></span>
<span><span class="co">#&gt; Ford Pantera L 1.419062</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-1">Example Output<a class="anchor" aria-label="anchor" href="#example-output-1"></a>
</h3>
<p>When using the LoF method with the default <code>minPts = 5</code>,
the function returns:</p>
<ul>
<li>
<code>Method</code>: “LoF”, indicating the method used.</li>
<li>
<code>Dataset</code>: The dataset name.</li>
<li>
<code>Variables</code>: The columns considered in the analysis.</li>
<li>
<code>Row</code>: Indices of rows identified as outliers.</li>
<li>
<code>Score</code>: LoF scores for each detected outlier.</li>
<li>
<code>Message</code>: A summary message indicating whether outliers
were detected.</li>
<li>
<code>minPts</code>: The parameter value used for the local
neighborhood.</li>
<li>
<code>Data</code>: Displays the five highest outliers in the data
used.</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"lof"</span><span class="op">)</span></span>
<span><span class="va">result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: LoF</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Row: 1 2 3 4 6 7 10 11 15 16 17 20 24 26 27 29 30 31 32</span></span>
<span><span class="co">#&gt; Outlier Score: 1.234384 1.109279 1.052523 1.434807 1.590262 1.031151 1.000967 1.002118 1.004441 1.2053 1.015402 1.013044 1.088952 1.002205 1.043699 1.419062 1.752452 1.94842 1.017775</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : minPts = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                     mpg cyl disp  hp      drat    wt  qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Maserati Bora  15.00000   8  301 335  3.540000 3.570 14.60  0  1    5    8</span></span>
<span><span class="co">#&gt; Ferrari Dino   19.70000   6  145 175 -5.146597 2.770 15.50  0  1    5    6</span></span>
<span><span class="co">#&gt; Valiant        18.10000   6  225 105  2.760000 3.460 20.22  1  0    3    1</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 54.27716   6  258 110  3.080000 3.215 19.44  1  0    3    1</span></span>
<span><span class="co">#&gt; Ford Pantera L 15.80000   8  351 264  4.220000 3.170 14.50  0  1    5    4</span></span>
<span><span class="co">#&gt;                  scores</span></span>
<span><span class="co">#&gt; Maserati Bora  1.948420</span></span>
<span><span class="co">#&gt; Ferrari Dino   1.752452</span></span>
<span><span class="co">#&gt; Valiant        1.590262</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 1.434807</span></span>
<span><span class="co">#&gt; Ford Pantera L 1.419062</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-1">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-1"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Sensitivity to minPts: The choice of <code>minPts</code>
significantly influences results. A value too small might result in
over-sensitivity, while a value too large might overlook smaller
clusters of anomalies.</p></li>
<li><p>Mixed Data Types: If the dataset contains categorical variables,
the method automatically switches from Euclidean to Gower distances for
calculating pairwise dissimilarities. Ensure the data is properly
encoded.</p></li>
<li><p>Interpreting LoF Scores: Scores greater than 1.5 typically
indicate potential outliers. Adjust the threshold based on the
characteristics of your dataset.</p></li>
</ol>
<p>To learn more about LoF &amp; Gower distance and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li>
<a href="https://towardsdatascience.com/local-outlier-factor-lof-algorithm-for-outlier-identification-8efb887d9843" class="external-link">Medium.com</a>
LoF Explained</li>
<li>
<a href="https://medium.com/analytics-vidhya/gowers-distance-899f9c4bd553" class="external-link">Gower
Distance</a> Gower Distance Explained</li>
<li><a href="https://scikit-learn.org/dev/modules/generated/sklearn.cluster.DBSCAN.html" class="external-link">DBSCAN
Documentation</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="mahalanobis">Mahalanobis<a class="anchor" aria-label="anchor" href="#mahalanobis"></a>
</h2>
<p>The Mahalanobis distance measures the distance of a point from the
center of a multivariate distribution while accounting for the
correlation between variables. This method identifies outliers by
calculating how far each point is from the data’s multivariate mean,
considering the covariance matrix of the data. This approach is
particularly useful when variables are highly correlated or have
different scales.</p>
<p>Before using the Mahalanobis distance, the function automatically
selects numeric columns from the dataset. Non-numeric variables are
excluded, ensuring compatibility with the method. The distances are then
calculated using the <a href="https://www.rdocumentation.org/packages/Routliers/versions/0.0.0.3/topics/outliers_mahalanobis" class="external-link">outliers_mahalanobis</a>
function from the <a href="https://cran.r-project.org/web/packages/Routliers/index.html" class="external-link">Routliers</a>
package. The Mahalanobis distances that are returned by the function
represent the distance from the point to the center of the
distribution.</p>
<div class="section level3">
<h3 id="customizing-the-alpha-parameter">Customizing the <code>alpha</code> parameter<a class="anchor" aria-label="anchor" href="#customizing-the-alpha-parameter"></a>
</h3>
<p>The <code>alpha</code> parameter determines the significance level
for outlier detection. The default <code>alpha</code> value is 0.1,
which corresponds to a 95% confidence level. The function calculates the
chi-squared distribution for these points, and removes those with
distances outside of the 95% confidence interval range.</p>
<p>Lower values (e.g., <code>alpha = 0.01</code>) result in stricter
thresholds, identifying fewer points as outliers while higher values are
less strict, identifying more observations as outliers. The function
will return the five observations with the largest outliers regardless
of the value of alpha. You can modify <code>alpha</code> as follows:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"mahalanobis"</span>, alpha <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: mahalanobis</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg disp hp drat wt qsec</span></span>
<span><span class="co">#&gt; Row: 3 9 16 30</span></span>
<span><span class="co">#&gt; Outlier Score: 21.23573 17.48584 17.54522 27.79833</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : alpha = 0.01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                          mpg      disp        hp      drat       wt      qsec</span></span>
<span><span class="co">#&gt; Ferrari Dino        19.70000  145.0000  175.0000 -5.146597  2.77000 15.500000</span></span>
<span><span class="co">#&gt; Datsun 710          22.80000 -468.2171   93.0000  3.850000 13.16772 18.610000</span></span>
<span><span class="co">#&gt; Lincoln Continental 10.40000  460.0000 -232.3693  3.000000  5.42400 17.820000</span></span>
<span><span class="co">#&gt; Merc 230            22.80000  140.8000   95.0000  3.920000  3.15000  3.655936</span></span>
<span><span class="co">#&gt; Hornet 4 Drive      54.27716  258.0000  110.0000  3.080000  3.21500 19.440000</span></span>
<span><span class="co">#&gt;                       scores</span></span>
<span><span class="co">#&gt; Ferrari Dino        27.79833</span></span>
<span><span class="co">#&gt; Datsun 710          21.23573</span></span>
<span><span class="co">#&gt; Lincoln Continental 17.54522</span></span>
<span><span class="co">#&gt; Merc 230            17.48584</span></span>
<span><span class="co">#&gt; Hornet 4 Drive      12.96992</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-2">Example Output<a class="anchor" aria-label="anchor" href="#example-output-2"></a>
</h3>
<p>When using the Mahalanobis method with the default
<code>alpha = 0.1</code>, the function returns:</p>
<ul>
<li>
<code>Method</code>: “mahalanobis”, indicating the method used.</li>
<li>
<code>Dataset</code>: The dataset name.</li>
<li>
<code>Variables</code>: The numeric columns considered.</li>
<li>
<code>Row</code>: Indices of rows identified as outliers.</li>
<li>
<code>Score</code>: Mahalanobis distance scores of detected
outliers.</li>
<li>
<code>Message</code>: A summary message indicating whether outliers
were detected.</li>
<li>
<code>Alpha</code>: The significance level used.</li>
<li>
<code>Data</code>: Displays the five highest outliers in the data
used.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"mahalanobis"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: mahalanobis</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg disp hp drat wt qsec</span></span>
<span><span class="co">#&gt; Row: 3 4 9 16 19 20 24 30</span></span>
<span><span class="co">#&gt; Outlier Score: 21.23573 12.96992 17.48584 17.54522 11.54579 10.88054 11.19061 27.79833</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : alpha = 0.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                          mpg      disp        hp      drat       wt      qsec</span></span>
<span><span class="co">#&gt; Ferrari Dino        19.70000  145.0000  175.0000 -5.146597  2.77000 15.500000</span></span>
<span><span class="co">#&gt; Datsun 710          22.80000 -468.2171   93.0000  3.850000 13.16772 18.610000</span></span>
<span><span class="co">#&gt; Lincoln Continental 10.40000  460.0000 -232.3693  3.000000  5.42400 17.820000</span></span>
<span><span class="co">#&gt; Merc 230            22.80000  140.8000   95.0000  3.920000  3.15000  3.655936</span></span>
<span><span class="co">#&gt; Hornet 4 Drive      54.27716  258.0000  110.0000  3.080000  3.21500 19.440000</span></span>
<span><span class="co">#&gt;                       scores</span></span>
<span><span class="co">#&gt; Ferrari Dino        27.79833</span></span>
<span><span class="co">#&gt; Datsun 710          21.23573</span></span>
<span><span class="co">#&gt; Lincoln Continental 17.54522</span></span>
<span><span class="co">#&gt; Merc 230            17.48584</span></span>
<span><span class="co">#&gt; Hornet 4 Drive      12.96992</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-2">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-2"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Numeric Data Only: The Mahalanobis method requires numeric
variables. Non-numeric columns are automatically excluded.</p></li>
<li><p>Multivariate Normality: This method assumes the data follows a
multivariate normal distribution. Deviations from normality or the
presence of extreme outliers may affect the results.</p></li>
</ol>
<p>To learn more about Mahalanobis distance and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li>
<a href="https://www.statisticshowto.com/mahalanobis-distance/" class="external-link">Statisticshowto.com</a>
Mahalanobis Distance Explained</li>
<li><a href="https://builtin.com/data-science/mahalanobis-distance" class="external-link">Builtin.com</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="iforest">iForest<a class="anchor" aria-label="anchor" href="#iforest"></a>
</h2>
<p>Isolation Forest (iForest) is an unsupervised machine learning
algorithm designed to detect anomalies in data and is implemented
through functions in the <a href="https://cran.r-project.org/web/packages/isotree/index.html" class="external-link">isotree</a>
package. It works by creating random partitions of the data and
measuring how quickly each point can be isolated. Points that are
isolated faster (using fewer splits) are more likely to be outliers.</p>
<p>The iForest algorithm is particularly well-suited for handling
high-dimensional data and works with both quantitative and categorical
variables. It is robust to noise and scales efficiently for large
datasets.</p>
<div class="section level3">
<h3 id="customizing-parameters">Customizing Parameters<a class="anchor" aria-label="anchor" href="#customizing-parameters"></a>
</h3>
<p>The iForest method allows customization of two main parameters:</p>
<p><code>ntrees</code>: The number of trees in the isolation forest. A
higher value increases precision but also computation time. Default is
100.</p>
<p><code>n</code>: The number of points to return as outliers. Default
is 5.</p>
<p>Here’s an example of how you can modify these parameters:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"iforest"</span>, ntrees <span class="op">=</span> <span class="fl">200</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: iForest</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Row: 1 2 3 4 9 16 19 29 30 31</span></span>
<span><span class="co">#&gt; Outlier Score: 0.5888639 0.5495799 0.5468237 0.5310991 0.5296226 0.5276686 0.5254197 0.520464 0.5148695 0.4996576</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : ntrees = 200</span></span>
<span><span class="co">#&gt; Option 2 : n = 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                     mpg cyl      disp        hp      drat       wt  qsec vs am</span></span>
<span><span class="co">#&gt; Ferrari Dino   19.70000   6  145.0000  175.0000 -5.146597  2.77000 15.50  0  1</span></span>
<span><span class="co">#&gt; Honda Civic    30.40000   4   75.7000 -240.5539  4.930000  1.61500 18.52  1  1</span></span>
<span><span class="co">#&gt; Datsun 710     22.80000   4 -468.2171   93.0000  3.850000 13.16772 18.61  1  1</span></span>
<span><span class="co">#&gt; Mazda RX4 Wag  52.22202   6  160.0000  110.0000  3.555697  2.87500 17.02  0  1</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 54.27716   6  258.0000  110.0000  3.080000  3.21500 19.44  1  0</span></span>
<span><span class="co">#&gt;                gear carb    scores</span></span>
<span><span class="co">#&gt; Ferrari Dino      5    6 0.5888639</span></span>
<span><span class="co">#&gt; Honda Civic       4    2 0.5495799</span></span>
<span><span class="co">#&gt; Datsun 710        4    1 0.5468237</span></span>
<span><span class="co">#&gt; Mazda RX4 Wag     4    4 0.5310991</span></span>
<span><span class="co">#&gt; Hornet 4 Drive    3    1 0.5296226</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-output-3">Example Output<a class="anchor" aria-label="anchor" href="#example-output-3"></a>
</h3>
<p>When using the iForest method with the default
<code>ntrees = 100</code> and <code>n = 5</code> the function
returns:</p>
<ul>
<li>
<code>Method</code>: “iForest”, indicating the method used.</li>
<li>
<code>Dataset</code>: The dataset name.</li>
<li>
<code>Variables</code>: The numeric columns considered.</li>
<li>
<code>Row</code>: Indices of rows identified as outliers.</li>
<li>
<code>Score</code>: Isolation scores for each detected outlier.</li>
<li>
<code>Message</code>: A summary message indicating whether outliers
were detected.</li>
<li>
<code>ntrees</code>: The number of trees in the isolation
forest</li>
<li>
<code>n</code>: The number of points to return as outliers</li>
<li>
<code>Data</code>: Displays the five highest outliers in the data
used.</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/multiOutliers.html">multiOutliers</a></span><span class="op">(</span><span class="va">mtcarsOutliers</span>, method <span class="op">=</span> <span class="st">"iforest"</span><span class="op">)</span></span>
<span><span class="va">result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Summary Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method: iForest</span></span>
<span><span class="co">#&gt; Dataset: mtcarsOutliers</span></span>
<span><span class="co">#&gt; Variables: mpg cyl disp hp drat wt qsec vs am gear carb</span></span>
<span><span class="co">#&gt; Row: 2 3 4 19 30</span></span>
<span><span class="co">#&gt; Outlier Score: 0.5771537 0.5524719 0.5426933 0.5410328 0.5378022</span></span>
<span><span class="co">#&gt; Message:  Outliers detected</span></span>
<span><span class="co">#&gt; Option 1 : ntrees = 100</span></span>
<span><span class="co">#&gt; Option 2 : n = 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">Dataset Information</span> <span style="color: #00BBBB;">─────────────────────────────────────────────────────────</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Five Largest Outliers Within the Provided Dataset:</span></span>
<span><span class="co">#&gt;                     mpg cyl      disp        hp      drat       wt  qsec vs am</span></span>
<span><span class="co">#&gt; Ferrari Dino   19.70000   6  145.0000  175.0000 -5.146597  2.77000 15.50  0  1</span></span>
<span><span class="co">#&gt; Datsun 710     22.80000   4 -468.2171   93.0000  3.850000 13.16772 18.61  1  1</span></span>
<span><span class="co">#&gt; Mazda RX4 Wag  52.22202   6  160.0000  110.0000  3.555697  2.87500 17.02  0  1</span></span>
<span><span class="co">#&gt; Honda Civic    30.40000   4   75.7000 -240.5539  4.930000  1.61500 18.52  1  1</span></span>
<span><span class="co">#&gt; Hornet 4 Drive 54.27716   6  258.0000  110.0000  3.080000  3.21500 19.44  1  0</span></span>
<span><span class="co">#&gt;                gear carb    scores</span></span>
<span><span class="co">#&gt; Ferrari Dino      5    6 0.5771537</span></span>
<span><span class="co">#&gt; Datsun 710        4    1 0.5524719</span></span>
<span><span class="co">#&gt; Mazda RX4 Wag     4    4 0.5426933</span></span>
<span><span class="co">#&gt; Honda Civic       4    2 0.5410328</span></span>
<span><span class="co">#&gt; Hornet 4 Drive    3    1 0.5378022</span></span></code></pre></div>
<p>Here is an example of graphical output from this function.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<p><img src="Multivariate_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="notes-and-considerations-3">Notes and Considerations<a class="anchor" aria-label="anchor" href="#notes-and-considerations-3"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Scalability: Isolation Forest is designed to handle large
datasets efficiently, making it suitable for high-dimensional data.
However, performance may depend on the ntrees parameter, as higher
values can increase computation time.</p></li>
<li><p>No Assumptions on Data Distribution: Unlike some statistical
methods, iForest does not assume a specific data distribution. This
makes it robust for detecting outliers in diverse datasets.</p></li>
<li><p>Handles Mixed Data Types: iForest can process both numeric and
categorical variables. However, ensure your data is properly encoded or
formatted as required by the <a href="https://cran.r-project.org/web/packages/isotree/index.html" class="external-link">isotree</a>
package.</p></li>
<li><p>Interpretation of Scores: Higher isolation scores indicate
stronger anomalies. You may need to determine an appropriate threshold
for your dataset when interpreting the results.</p></li>
</ol>
<p>To learn more about Isolation Forest and how it’s used in
multivariate outlier detection, visit these resources:</p>
<ul>
<li>
<a href="https://medium.com/@limyenwee_19946/unsupervised-outlier-detection-with-isolation-forest-eab398c593b2" class="external-link">Medium.com</a>
iForest Explained</li>
<li><a href="https://www.youtube.com/watch?v=O9VvmWj-JAk" class="external-link">Andy McDonald
on YouTube</a></li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Caleb Henning, Larissa Xu, Angelica Crown, Ernie Little, Braeden Falzarano, Ral Reyes, Tegh Singh.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
