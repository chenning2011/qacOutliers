[{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"what-are-multivariate-outliers-how-do-you-detect-them","dir":"Articles","previous_headings":"","what":"What are multivariate outliers? How do you detect them?","title":"Multivariate","text":"multivariate outlier outlier can detected looking two variables combination. graph shows examples multivariate outliers. data graph taken Salaries dataset carData package.  red dots multivariate outliers. point labelled 1 graph clear example multivariate outlier. person PhD 22 years, normal value variable, makes $62,884, also normal value salary. However, combining two features, person 22 years since PhD makes $62,884 making much less professors within experience range. outliers graph detected using LoF method, detail method can provided . package specifically focuses four different methods finding multivariate outliers: kNN, LoF, mahalanobis distance, iForest.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"knn","dir":"Articles","previous_headings":"","what":"kNN","title":"Multivariate","text":"kNN calculates distances data point k-nearest neighbors assigns outlier score based distance. principle guides kNN outliers lay far away neighbours, distances interpreted within context. variables data may much larger ranges others (ex. variable range 1-10 another range -10000 10000), data standardized calculating distances. example distances first 5 rows mtcarsOutliers, dataset included package. distances calculated, average row calculated. average scores 5 rows shown . step ’s important standardize data finding distances. function, next step involves creating threshold declaring point outlier. calculate threshold, function takes average row (row’s average calculated), adds 2 times standard deviation row number. case, threshold number . Outliers considered points score calculated threshold. case, outliers shown .","code":"#>           [,1]     [,2]     [,3]     [,4]     [,5] #> [1,] 1.5229770 2.102410 2.265502 2.651939 2.664224 #> [2,] 1.5031299 1.509144 1.522977 1.568453 1.608401 #> [3,] 1.2561178 1.503130 1.728826 1.817606 1.983652 #> [4,] 0.3490918 1.045627 1.163944 1.331333 1.351668 #> [5,] 4.7397611 5.019562 5.024754 5.026238 5.106755 #> [1] 2.241410 1.542421 1.657866 1.048333 4.983414 #> [1] 5.657686 #>  #> Method: kNN #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 11 19 #> Outlier Score: 547.8248 393.1049 #> Message:  Outliers detected #> Option 1 : k = 5 #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl      disp        hp     drat    wt #> Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440 #> Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615 #> Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440 #> Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440 #> Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570 #>                       qsec vs am      gear carb   scores #> Merc 280C         18.90000  1  0 4.0000000    4 547.8248 #> Honda Civic       18.52000  1  1 4.0000000    2 393.1049 #> Merc 280          18.30000  1  0 4.0000000    4 318.1242 #> Hornet Sportabout 17.02000  0  0 3.0000000    2 189.8207 #> Maserati Bora     33.90273  0  1 0.9829575    8 117.9942"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"customizing-the-k-parameter","dir":"Articles","previous_headings":"kNN","what":"Customizing the k parameter","title":"Multivariate","text":"value k tells function many points consider neighbors identifying distances points. default value, 5, finds distance point 5 points closest point. choice k significantly impacts results, smaller values generally sensitive outliers. can supply value k, may change results function.","code":"multiOutliers(mtcarsOutliers, method = \"kNN\", k = 10) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: kNN #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 11 19 #> Outlier Score: 568.7642 441.0597 #> Message:  Outliers detected #> Option 1 : k = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl      disp        hp     drat    wt #> Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440 #> Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615 #> Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440 #> Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440 #> Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570 #>                       qsec vs am      gear carb   scores #> Merc 280C         18.90000  1  0 4.0000000    4 568.7642 #> Honda Civic       18.52000  1  1 4.0000000    2 441.0597 #> Merc 280          18.30000  1  0 4.0000000    4 330.3313 #> Hornet Sportabout 17.02000  0  0 3.0000000    2 230.4534 #> Maserati Bora     33.90273  0  1 0.9829575    8 145.8174"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"example-output","dir":"Articles","previous_headings":"kNN","what":"Example Output","title":"Multivariate","text":"using kNN method default k=5, function returns: Method: “kNN”, indicating method used. Dataset: dataset name. Variables: numeric columns considered outlier detection. Row: Indices rows identified outliers. Score: Average kNN distance scores detected outliers. Message: summary message indicating whether outliers detected. k: number nearest neighbors considered. Data: Displays five highest outliers data used. example graphical output function.","code":"result <- multiOutliers(mtcarsOutliers, method = \"kNN\") print(result) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: kNN #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 11 19 #> Outlier Score: 547.8248 393.1049 #> Message:  Outliers detected #> Option 1 : k = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl      disp        hp     drat    wt #> Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440 #> Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615 #> Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440 #> Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440 #> Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570 #>                       qsec vs am      gear carb   scores #> Merc 280C         18.90000  1  0 4.0000000    4 547.8248 #> Honda Civic       18.52000  1  1 4.0000000    2 393.1049 #> Merc 280          18.30000  1  0 4.0000000    4 318.1242 #> Hornet Sportabout 17.02000  0  0 3.0000000    2 189.8207 #> Maserati Bora     33.90273  0  1 0.9829575    8 117.9942 plot(result) #> Loading required package: grid"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"notes-and-considerations","dir":"Articles","previous_headings":"kNN","what":"Notes and Considerations","title":"Multivariate","text":"Numeric Data : kNN method requires numeric variables. Non-numeric columns automatically excluded. Robustness: kNN assume specific distribution data, robust non-normality, making better tool handle non-normal data outlier detection methods. learn kNN ’s used multivariate outlier detection, visit resources: GeeksforGeeks.com Dualitytech.com StatQuest","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"local-outlier-factor-lof","dir":"Articles","previous_headings":"","what":"Local outlier factor (LoF)","title":"Multivariate","text":"Local Outlier Factor (LoF) method detects anomalies comparing density data points local neighborhood. Points significantly lower density neighbors flagged potential outliers. dbscan package used implementation, calculates LoF scores data point. Scores certain threshold (typically > 1) indicative stronger outliers. LoF particularly useful datasets clusters varying density, considers local density assessing outlierness. supports numeric categorical variables, using Gower distance mixed data types. example scores using mtcarsOutliers dataset included package.","code":"library(dbscan) #>  #> Attaching package: 'dbscan' #> The following object is masked from 'package:stats': #>  #>     as.dendrogram data <- mtcarsOutliers[-1]  data_scaled <- scale(data) lof_scores <- lof(as.matrix(data_scaled), minPts = 5)  head(lof_scores, 5) #> [1] 1.1995026 1.0700106 0.9325731 1.4719657 3.3479437"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"customizing-the-minpts-parameter","dir":"Articles","previous_headings":"Local outlier factor (LoF)","what":"Customizing the minPts Parameter","title":"Multivariate","text":"LoF method allows customization minPts parameter, minimum number points local neighborhood. Larger values result broader neighborhoods may reduce sensitivity smaller clusters. Default 5. can adjust parameters suit dataset. ’s example:","code":"multiOutliers(mtcarsOutliers, method = \"LoF\", minPts = 10) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: LoF #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 11 12 20 31 32 #> Outlier Score: 2.28365 2.719583 2.560179 1.530304 1.563598 1.804971 1.567824 2.950466 1.574599 #> Message:  Outliers detected #> Option 1 : minPts = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp      hp     drat        wt     qsec #> Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273 #> Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000 #> Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000 #> Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000 #> Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000 #>                          vs am      gear carb   scores #> Maserati Bora      0.000000  1 0.9829575    8 2.950466 #> Duster 360         0.000000  0 3.0000000    4 2.719583 #> Merc 230          -8.556805  0 4.0000000    2 2.560179 #> Hornet Sportabout  0.000000  0 3.0000000    2 2.283650 #> Merc 450SE         0.000000  0 3.0000000    3 1.804971"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"example-output-1","dir":"Articles","previous_headings":"Local outlier factor (LoF)","what":"Example Output","title":"Multivariate","text":"using LoF method default minPts = 5, function returns: Method: “LoF”, indicating method used. Dataset: dataset name. Variables: columns considered analysis. Row: Indices rows identified outliers. Score: LoF scores detected outlier. Message: summary message indicating whether outliers detected. minPts: parameter value used local neighborhood. Data: Displays five highest outliers data used. example graphical output function.","code":"result <- multiOutliers(mtcarsOutliers, method = \"LoF\") result #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: LoF #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 11 12 20 31 32 #> Outlier Score: 2.28365 2.719583 2.560179 1.530304 1.563598 1.804971 1.567824 2.950466 1.574599 #> Message:  Outliers detected #> Option 1 : minPts = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp      hp     drat        wt     qsec #> Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273 #> Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000 #> Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000 #> Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000 #> Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000 #>                          vs am      gear carb   scores #> Maserati Bora      0.000000  1 0.9829575    8 2.950466 #> Duster 360         0.000000  0 3.0000000    4 2.719583 #> Merc 230          -8.556805  0 4.0000000    2 2.560179 #> Hornet Sportabout  0.000000  0 3.0000000    2 2.283650 #> Merc 450SE         0.000000  0 3.0000000    3 1.804971 plot(result)"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"notes-and-considerations-1","dir":"Articles","previous_headings":"Local outlier factor (LoF)","what":"Notes and Considerations","title":"Multivariate","text":"Sensitivity minPts: choice minPts significantly influences results. value small might result -sensitivity, value large might overlook smaller clusters anomalies. Mixed Data Types: dataset contains categorical variables, method automatically switches Gower distance calculating pairwise dissimilarities. Ensure data properly encoded. Interpreting LoF Scores: Scores greater 1.5 typically indicate potential outliers. Adjust threshold based characteristics dataset. learn Mahalanobis distance ’s used multivariate outlier detection, visit resources: Medium.com DBSCAN Documentation","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"mahalanobis","dir":"Articles","previous_headings":"","what":"Mahalanobis","title":"Multivariate","text":"Mahalanobis distance measures distance point center multivariate distribution accounting correlation variables. method identifies outliers calculating far point data’s multivariate mean, considering covariance matrix data. approach particularly useful variables highly correlated different scales. using Mahalanobis distance, function automatically selects numeric columns dataset. Non-numeric variables excluded, ensuring compatibility method. distances calculated using outliers_mahalanobis function Routliers package. example calculating Mahalanobis distances mtcarsOutliers dataset included package: outliers identified function indices returned: Outliers identified comparing Mahalanobis distance point threshold derived chi-squared distribution. Points distances greater critical value specified significance level (alpha) flagged outliers. default alpha 0.05, corresponds 95% confidence level. can customize value adjust sensitivity detection. threshold dataset using default alpha = 0.05:","code":"#>         Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive  #>          7.217210          3.682371          5.829785          1.981340  #> Hornet Sportabout  #>         25.022031 #> Hornet Sportabout        Duster 360          Merc 230          Merc 280  #>                 5                 7                 9                10  #>    Toyota Corolla     Maserati Bora        Volvo 142E  #>                20                31                32 #> [1] 18.30704"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"customizing-the-alpha-parameter","dir":"Articles","previous_headings":"Mahalanobis","what":"Customizing the alpha parameter","title":"Multivariate","text":"alpha parameter outliers_mahalanobis determines significance level outlier detection. Lower values (e.g., alpha = 0.01) result stricter thresholds, identifying fewer points outliers. can modify alpha follows:","code":"multiOutliers(mtcarsOutliers, method = \"mahalanobis\", alpha = 0.01) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: mahalanobis #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 12 31 32 #> Outlier Score: 25.11784 29.58581 27.30969 26.99406 27.95683 25.39721 #> Message:  Outliers detected #> Option 1 : alpha = 0.01 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                    mpg cyl  disp  hp     drat        wt     qsec        vs am #> Duster 360    14.30000   8 360.0 245 18.14468  3.570000 15.84000  0.000000  0 #> Maserati Bora 15.00000   8 301.0 335  3.54000  3.570000 33.90273  0.000000  1 #> Merc 230      22.80000   4 140.8  95  3.92000 -4.541341 22.90000 -8.556805  0 #> Merc 450SE    54.17757   8 275.8 180  3.07000  4.070000 17.40000  0.000000  0 #> Volvo 142E    21.40000   4 121.0 109  4.11000  2.780000 18.60000  1.000000  1 #>                    gear      carb   scores #> Duster 360    3.0000000   4.00000 29.58581 #> Maserati Bora 0.9829575   8.00000 27.95683 #> Merc 230      4.0000000   2.00000 27.30969 #> Merc 450SE    3.0000000   3.00000 26.99406 #> Volvo 142E    4.0000000 -12.91235 25.39721"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"example-output-2","dir":"Articles","previous_headings":"Mahalanobis","what":"Example Output","title":"Multivariate","text":"using Mahalanobis method default alpha = 0.05, function returns: Method: “mahalanobis”, indicating method used. Dataset: dataset name. Variables: numeric columns considered. Row: Indices rows identified outliers. Score: Mahalanobis distance scores detected outliers. Message: summary message indicating whether outliers detected. Alpha: significance level used. Data: Displays five highest outliers data used. example graphical output function.","code":"result <- multiOutliers(mtcarsOutliers, method = \"mahalanobis\") print(result) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: mahalanobis #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 12 20 31 32 #> Outlier Score: 25.11784 29.58581 27.30969 19.22256 26.99406 21.46034 27.95683 25.39721 #> Message:  Outliers detected #> Option 1 : alpha = 0.1 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                    mpg cyl  disp  hp     drat        wt     qsec        vs am #> Duster 360    14.30000   8 360.0 245 18.14468  3.570000 15.84000  0.000000  0 #> Maserati Bora 15.00000   8 301.0 335  3.54000  3.570000 33.90273  0.000000  1 #> Merc 230      22.80000   4 140.8  95  3.92000 -4.541341 22.90000 -8.556805  0 #> Merc 450SE    54.17757   8 275.8 180  3.07000  4.070000 17.40000  0.000000  0 #> Volvo 142E    21.40000   4 121.0 109  4.11000  2.780000 18.60000  1.000000  1 #>                    gear      carb   scores #> Duster 360    3.0000000   4.00000 29.58581 #> Maserati Bora 0.9829575   8.00000 27.95683 #> Merc 230      4.0000000   2.00000 27.30969 #> Merc 450SE    3.0000000   3.00000 26.99406 #> Volvo 142E    4.0000000 -12.91235 25.39721 plot(result)"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"notes-and-considerations-2","dir":"Articles","previous_headings":"Mahalanobis","what":"Notes and Considerations","title":"Multivariate","text":"Numeric Data : Mahalanobis method requires numeric variables. Non-numeric columns automatically excluded. Multivariate Normality: method assumes data follows multivariate normal distribution. Deviations normality presence extreme outliers may affect results. learn Mahalanobis distance ’s used multivariate outlier detection, visit resources: Statisticshowto.com Builtin.com","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"iforest","dir":"Articles","previous_headings":"","what":"iForest","title":"Multivariate","text":"Isolation Forest (iForest) unsupervised machine learning algorithm designed detect anomalies data implemented using isotree package. works creating random partitions data measuring quickly point can isolated. Points isolated faster (using fewer splits) likely outliers. iForest algorithm particularly well-suited handling high-dimensional data works quantitative categorical variables. robust noise scales efficiently large datasets. example scores using mtcarsOutliers dataset included package.","code":"library(isotree) #> Warning: package 'isotree' was built under R version 4.4.2 data <- mtcarsOutliers[-1]  isolation_forest_model <- isolation.forest(data, ntrees = 100) data$iso_score <- predict(isolation_forest_model, data)  head(data$iso_score, 5) #> [1] 0.4249880 0.3782837 0.3807095 0.3695911 0.5066493"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"customizing-parameters","dir":"Articles","previous_headings":"iForest","what":"Customizing Parameters","title":"Multivariate","text":"iForest method allows customization two main parameters: ntrees: number trees isolation forest. higher value increases precision also computation time. Default 100. n: number points return outliers. Default 5. ’s example can modify parameters:","code":"multiOutliers(mtcarsOutliers, method = \"iForest\", ntrees = 200, n = 10) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: iForest #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 12 19 20 29 31 32 #> Outlier Score: 0.5932919 0.5876694 0.5168765 0.5038969 0.4751465 0.4591736 0.4582887 0.4562152 0.4447788 0.4408235 #> Message:  Outliers detected #> Option 1 : ntrees = 200 #> Option 2 : n = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp        hp     drat        wt #> Maserati Bora     15.00000  8.000000 301.0  335.0000 3.540000  3.570000 #> Merc 230          22.80000  4.000000 140.8   95.0000 3.920000 -4.541341 #> Toyota Corolla    33.90000  4.000000  71.1   65.0000 4.220000  1.835000 #> Hornet Sportabout 18.70000 -4.137792 360.0  446.9140 3.150000  3.440000 #> Merc 280          44.30673  6.000000 167.6 -238.7728 4.560312  3.440000 #>                       qsec        vs am      gear      carb    scores #> Maserati Bora     33.90273  0.000000  1 0.9829575  8.000000 0.5932919 #> Merc 230          22.90000 -8.556805  0 4.0000000  2.000000 0.5876694 #> Toyota Corolla    19.90000  6.993352  1 4.0000000 -7.344032 0.5168765 #> Hornet Sportabout 17.02000  0.000000  0 3.0000000  2.000000 0.5038969 #> Merc 280          18.30000  1.000000  0 4.0000000  4.000000 0.4751465"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"example-output-3","dir":"Articles","previous_headings":"iForest","what":"Example Output","title":"Multivariate","text":"using iForest method default ntrees = 100 n = 5 function returns: Method: “iForest”, indicating method used. Dataset: dataset name. Variables: numeric columns considered. Row: Indices rows identified outliers. Score: Isolation scores detected outlier. Message: summary message indicating whether outliers detected. ntrees: number trees isolation forest n: number points return outliers Data: Displays five highest outliers data used. example graphical output function.","code":"result <- multiOutliers(mtcarsOutliers, method = \"iForest\") result #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: iForest #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 9 20 31 32 #> Outlier Score: 0.5912855 0.5673572 0.5386362 0.4858491 0.4728747 #> Message:  Outliers detected #> Option 1 : ntrees = 100 #> Option 2 : n = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                    mpg       cyl  disp      hp drat        wt     qsec #> Merc 230          22.8  4.000000 140.8  95.000 3.92 -4.541341 22.90000 #> Maserati Bora     15.0  8.000000 301.0 335.000 3.54  3.570000 33.90273 #> Toyota Corolla    33.9  4.000000  71.1  65.000 4.22  1.835000 19.90000 #> Hornet Sportabout 18.7 -4.137792 360.0 446.914 3.15  3.440000 17.02000 #> Volvo 142E        21.4  4.000000 121.0 109.000 4.11  2.780000 18.60000 #>                          vs am      gear       carb    scores #> Merc 230          -8.556805  0 4.0000000   2.000000 0.5912855 #> Maserati Bora      0.000000  1 0.9829575   8.000000 0.5673572 #> Toyota Corolla     6.993352  1 4.0000000  -7.344032 0.5386362 #> Hornet Sportabout  0.000000  0 3.0000000   2.000000 0.4858491 #> Volvo 142E         1.000000  1 4.0000000 -12.912355 0.4728747 plot(result)"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Multivariate.html","id":"notes-and-considerations-3","dir":"Articles","previous_headings":"iForest","what":"Notes and Considerations","title":"Multivariate","text":"Scalability: Isolation Forest designed handle large datasets efficiently, making suitable high-dimensional data. However, performance may depend ntrees parameter, higher values can increase computation time. Assumptions Data Distribution: Unlike statistical methods, iForest assume specific data distribution. makes robust detecting outliers diverse datasets. Handles Mixed Data Types: iForest can process numeric categorical variables. However, ensure data properly encoded formatted required isotree package. Interpretation Scores: Higher isolation scores indicate stronger anomalies. may need determine appropriate threshold dataset interpreting results. learn Isolation Forest ’s used multivariate outlier detection, visit resources: Medium.com Andy McDonald YouTube","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/qacOutliers.html","id":"what-are-outliers","dir":"Articles","previous_headings":"","what":"What are outliers?","title":"qacOutliers","text":"Outliers–also known anamolies, abnormalities, discordants, deviants–observations differ significantly rest observations dataset. many different reasons outliers can exist dataset, including natural variation population measurement error. Natural variations can seen many different ways. example, dataset people’s salaries includes random sample people, observations billionaires, much larger salary average person, distort data. Measurement experimental errors can occur data collection process. example, experiment recording people’s heights, measurement accidentally entered 52’ instead 5’2”, value outlier. isn’t person abnormally tall, height recorded incorrectly.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/qacOutliers.html","id":"how-can-you-detect-outliers-how-can-i-use-this-package-to-detect-outliers","dir":"Articles","previous_headings":"","what":"How can you detect outliers? How can I use this package to detect outliers?","title":"qacOutliers","text":"Detecting outliers, like many techniques data science, art science. many different reasons outliers exist, many different ways detect . package includes seven commonly used methods univariate multivariate outlier detection. See linked pages information specific methods. seven methods distinct methods identifying calculating outliers, ranging visualizing data standardizing calculating scores variable identify observations mathematically furthest away rest data. Although methods return observations classified outliers respective functions, ’s important always look underlying data understand picked outliers, truly outliers, might values . -provide information load library supress messages show loading package","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/qacOutliers.html","id":"why-should-we-detect-outliers","dir":"Articles","previous_headings":"","what":"Why should we detect outliers?","title":"qacOutliers","text":"many reasons outliers dataset, ’s always important take moment understand potential outliers within data. techniques utilize averages heavily effected presence outliers, ’s extra important look outliers taking mean variables dataset. Additionally, outliers can generated measurement errors, provide context issues may arise data collection. findings especially helpful collecting data. aware issues data collection within datasets, techniques help identify points mistakes may made.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/qacOutliers.html","id":"what-should-you-do-with-outliers-once-you-detect-them","dir":"Articles","previous_headings":"","what":"What should you do with outliers once you detect them?","title":"qacOutliers","text":"depends lot factors, including cause outlier (known), magnitude outlier, whether believe detected outliers truly outliers. many reasons outliers exist, detected outliers may really outliers, package allows decide want proceed. run one functions, can extract row numbers detected outliers carefully inspect data decide want detected outliers. example multivariate outliers detected LoF method, using mtcarsOutliers, dataset included package. LoF function detected nine outliers within dataset. output, can identify rows outliers , extract inspect observations. Looking dataset, can easily see lot detected outliers likely true outliers. values positive, negative values likely result measurement error can removed (takes Hornet Sportabout, Merc 280C, Merc 280, Merc 230, Toyota Corrolla, Volvo 142E). values look much larger , require closer look distributions values variables. better understood underlying data, can decide whether remove values data conducting analysis.","code":"results <- multiOutliers(mtcarsOutliers, method = \"LoF\") results #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: LoF #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 11 12 20 31 32 #> Outlier Score: 2.28365 2.719583 2.560179 1.530304 1.563598 1.804971 1.567824 2.950466 1.574599 #> Message:  Outliers detected #> Option 1 : minPts = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp      hp     drat        wt     qsec #> Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273 #> Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000 #> Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000 #> Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000 #> Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000 #>                          vs am      gear carb   scores #> Maserati Bora      0.000000  1 0.9829575    8 2.950466 #> Duster 360         0.000000  0 3.0000000    4 2.719583 #> Merc 230          -8.556805  0 4.0000000    2 2.560179 #> Hornet Sportabout  0.000000  0 3.0000000    2 2.283650 #> Merc 450SE         0.000000  0 3.0000000    3 1.804971 index <- results$Row subset <- mtcarsOutliers[index,] subset #>                        mpg       cyl      disp        hp      drat        wt #> Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140  3.150000  3.440000 #> Duster 360        14.30000  8.000000  360.0000  245.0000 18.144679  3.570000 #> Merc 230          22.80000  4.000000  140.8000   95.0000  3.920000 -4.541341 #> Merc 280          44.30673  6.000000  167.6000 -238.7728  4.560312  3.440000 #> Merc 280C         17.80000  6.000000 -459.2495  123.0000  3.920000  3.440000 #> Merc 450SE        54.17757  8.000000  275.8000  180.0000  3.070000  4.070000 #> Toyota Corolla    33.90000  4.000000   71.1000   65.0000  4.220000  1.835000 #> Maserati Bora     15.00000  8.000000  301.0000  335.0000  3.540000  3.570000 #> Volvo 142E        21.40000  4.000000  121.0000  109.0000  4.110000  2.780000 #>                       qsec        vs am      gear       carb #> Hornet Sportabout 17.02000  0.000000  0 3.0000000   2.000000 #> Duster 360        15.84000  0.000000  0 3.0000000   4.000000 #> Merc 230          22.90000 -8.556805  0 4.0000000   2.000000 #> Merc 280          18.30000  1.000000  0 4.0000000   4.000000 #> Merc 280C         18.90000  1.000000  0 4.0000000   4.000000 #> Merc 450SE        17.40000  0.000000  0 3.0000000   3.000000 #> Toyota Corolla    19.90000  6.993352  1 4.0000000  -7.344032 #> Maserati Bora     33.90273  0.000000  1 0.9829575   8.000000 #> Volvo 142E        18.60000  1.000000  1 4.0000000 -12.912355"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Univariate.html","id":"what-are-univariate-outliers-how-do-you-detect-them","dir":"Articles","previous_headings":"","what":"What are univariate outliers? How do you detect them?","title":"Univariate","text":"Univariate outliers data points consisting extreme value one variable. values lie far dataset’s central tendency. graphical example univariate outlier Salaries dataset carData package. outlier shown red.  many different methods can used detect univariate outliers, package detects univariate outliers using three methods: creating boxplot, using Grubbs’ test, median absolute deviation test. function detects outliers specified column(s) provides following output: (1) value detected outliers corresponding row numbers. (2) graphical visualization showing distribution data outliers highlighted according selected method.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/articles/Univariate.html","id":"boxplot-method","dir":"Articles","previous_headings":"","what":"Boxplot Method","title":"Univariate","text":"boxplot method univariate outlier detection identifies extreme data points examining distribution values using boxplot. method, “whiskers” boxplot represent range typical values within dataset. function, outliers defined values fall outside whiskers, calculated Q1−1.58×IQR lower bound Q3+1.58×IQR upper bound, Q1 Q3 first third quartiles, respectively, IQR interquartile range (difference Q3 Q1) allow broader range different threshold detecting extreme values. 1.58 length whiskers multiple IQR. method helps quickly identify potential outliers, plotted individually can indicate unusual problematic data points may warrant investigation.  output provide identified outliers along corresponding row numbers, graphical representation generated outliers highlighted red.","code":"object2 <- univOutliers(data = mtcars, x= \"wt\", method = \"boxplot\") plot(object2)  # Plotting the object with 'mtcars' dataset print(object2)  # Printing the outliers and methods #> Loading required package: cli #> Loading required package: knitr #>  #> ── Method Chosen: boxplot ────────────────────────────────────────────────────── #> Variable: wt #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      16            5.424      #>      17            5.345"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Univariate.html","id":"grubbs-test","dir":"Articles","previous_headings":"","what":"Grubb’s Test","title":"Univariate","text":"Grubbs’ Test simple technique iteratively identifies outliers testing hypothesis largest smallest value outlier. Grubbs’ test requires data normally distributed relies mean standard deviation. output Grubbs’ test provide identified outliers corresponding row numbers. method uses Shapiro-Wilk test (shapiro.test) normality. p-value normality test less 0.05, issues warning normality high p-value affect accuracy Grubbs’ Test. output Grubbs’ test provide identified outliers, corresponding row numbers. method uses Shapiro-Wilk test (shapiro.test) normality. p-value normality test less 0.05, issues warning normality high p-value affect accuracy Grubbs’ Test.","code":"# TO TEST NORMAL DIST W OUTLIER FOR GRUBBS set.seed(42) normal_data <- rnorm(100, mean = 50, sd = 5)  # Normal distribution data_with_outlier <- c(normal_data, 70)  # Add a clear outlier (100) data_frame <- data.frame(values = data_with_outlier) object_normal_outlier <- univOutliers(data = data_frame, x = \"values\", method = \"grubbs\") #plot(object_normal_outlier)  # Plotting the object with the outlier print(object_normal_outlier)  # Printing the outliers and methods #>  #> ── Method Chosen: grubbs ─────────────────────────────────────────────────────── #> Variable: values #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>     101             70 object3 <- univOutliers(data = mtcars, x = \"carb\", method = \"grubbs\") #> Warning in grubbs_test(column_data): Data is not normally distributed. Grubbs' #> test may not be appropriate. #plot(object3)  # Plotting the object with 'mtcars' dataset print(object3)  # Printing the outliers and methods #>  #> ── Method Chosen: grubbs ─────────────────────────────────────────────────────── #> Variable: carb #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      31              8"},{"path":"https://github.com/chenning2011/qacOutliers/articles/Univariate.html","id":"mad","dir":"Articles","previous_headings":"","what":"MAD","title":"Univariate","text":"MAD (Median Absolute Deviation) method univariate outlier detection identifies outliers based robust measure variability, median absolute deviation. method, red line represents median values target vector. upper CI limit median + 3MAD lower CI limit median - 3MAD. points outside confidence interval outliers detected MAD method. output provide identified outliers along corresponding row numbers, graphical representation generated outliers highlighted red.","code":"object <- univOutliers(data = mtcars, x=\"carb\", method = \"mad\") #plot(object)  # Plotting the object with 'mtcars' dataset print(object)  # Printing the outliers and methods #>  #> ── Method Chosen: mad ────────────────────────────────────────────────────────── #> Variable: carb #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      31              8"},{"path":"https://github.com/chenning2011/qacOutliers/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Caleb Henning. Author, maintainer. Larissa Xu. Author. Angelica Crown. Author. Ernie Little. Author. Braeden Falzarano. Author. Ral Reyes. Author. Tegh Singh. Author.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Henning C, Xu L, Crown , Little E, Falzarano B, Reyes R, Singh T (2024). qacOutliers: Identification Multivariate Univariate Outliers. R package version 0.0.0.9000, https://github.com/chenning2011/qacOutliers.","code":"@Manual{,   title = {qacOutliers: Identification of Multivariate and Univariate Outliers},   author = {Caleb Henning and Larissa Xu and Angelica Crown and Ernie Little and Braeden Falzarano and Ral Reyes and Tegh Singh},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://github.com/chenning2011/qacOutliers}, }"},{"path":"https://github.com/chenning2011/qacOutliers/index.html","id":"qacoutliers","dir":"","previous_headings":"","what":"Identification of Multivariate and Univariate Outliers","title":"Identification of Multivariate and Univariate Outliers","text":"goal qacOutliers detect multivariate univariate outliers using seven different methods. package consolidates methods multiple different R packages makes easily accessible.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Identification of Multivariate and Univariate Outliers","text":"can install development version qacOutliers GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"https://github.com/chenning2011/qacOutliers/\")"},{"path":"https://github.com/chenning2011/qacOutliers/index.html","id":"how-to-use","dir":"","previous_headings":"","what":"How to use","title":"Identification of Multivariate and Univariate Outliers","text":"learn use package, outliers , different functions available package, visit Getting Started, Multivariate, Univariate vignettes. can find specific functions work Documentation page.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Caleb Henning, Tegh Singh, Larissa Xu, Angelica Crown, Ernie Little, Ral Reyes, Braeden Falzarano Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/irisOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"iris dataset with outliers — irisOutliers","title":"iris dataset with outliers — irisOutliers","text":"iris dataset base R generated outliers","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/irisOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"iris dataset with outliers — irisOutliers","text":"","code":"irisOutliers"},{"path":"https://github.com/chenning2011/qacOutliers/reference/irisOutliers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"iris dataset with outliers — irisOutliers","text":"data frame 150 rows 5 variables: Sepal.Length double. DESCRIPTION. Sepal.Width double. DESCRIPTION. Petal.Length double. DESCRIPTION. Petal.Width double. DESCRIPTION. Species integer. DESCRIPTION.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/irisOutliers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"iris dataset with outliers — irisOutliers","text":"iris dataset base R generated outliers. Outliers generated using generateOutliers function outForest package.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/mtcarsOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"mtcars dataset from base R with outliers — mtcarsOutliers","title":"mtcars dataset from base R with outliers — mtcarsOutliers","text":"Modified version mtcars generated outliers.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/mtcarsOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mtcars dataset from base R with outliers — mtcarsOutliers","text":"","code":"mtcarsOutliers"},{"path":"https://github.com/chenning2011/qacOutliers/reference/mtcarsOutliers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"mtcars dataset from base R with outliers — mtcarsOutliers","text":"data frame 32 rows 11 variables: mpg double. miles per gallon cyl double. number cylinders disp double. displacement (cu..) hp double. gross horsepower drat double. rear axle ratio wt double. weight (1000 lbs) qsec double. 1/4 mile time vs double. engine (0 = v-shaped, 1 = straight) double. transmission (0 = automatic, 1 = manual) gear double. number forward gears carb double. number carburetors","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/mtcarsOutliers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"mtcars dataset from base R with outliers — mtcarsOutliers","text":"mtcars dataset comes base R. Outliers generated using generateOutliers function outForest package.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/multiOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Outlier Detection — multiOutliers","title":"Multivariate Outlier Detection — multiOutliers","text":"Identifies multivariate outliers using four different methods.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/multiOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Outlier Detection — multiOutliers","text":"","code":"multiOutliers(   data,   varlist = names(data),   method,   minPts = 10,   k = 5,   threshold = 0.95,   alpha = 0.1,   ntrees = 100,   n = 5,   na.rm = TRUE,   ... )"},{"path":"https://github.com/chenning2011/qacOutliers/reference/multiOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Outlier Detection — multiOutliers","text":"data data frame varlist list numeric variables method character, supplies method used outlier detection. Methods LoF, kNN, mahalanobis, iForest minPts (optional) numeric, minimum points used LoF outlier detection. Default value 5 k (optional) k value used kNN method outlier detection. Default value 5 threshold (optional) threshold used kNN outlier detection. Default value 0.95 alpha (optional) alpha used mahalanobis distance outlier detection. Default value 0.1 ntrees (optional) number trees used iForest outlier detection. Default value 100 n (optional) number points take outliers iForest outlier detection. Default value 5 na.rm (optional) logical, specifies whether remove NA values. Defaults TRUE","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/multiOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Outlier Detection — multiOutliers","text":"method used, dataset used, variables used outliers detected, indices detected outliers, scores outliers, values optional parameters","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/multiOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Outlier Detection — multiOutliers","text":"","code":"multiOutliers(mtcarsOutliers, method=\"mahalanobis\", alpha=0.1) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: mahalanobis #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 12 20 31 32 #> Outlier Score: 25.11784 29.58581 27.30969 19.22256 26.99406 21.46034 27.95683 25.39721 #> Message:  Outliers detected #> Option 1 : alpha = 0.1 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                    mpg cyl  disp  hp     drat        wt     qsec        vs am #> Duster 360    14.30000   8 360.0 245 18.14468  3.570000 15.84000  0.000000  0 #> Maserati Bora 15.00000   8 301.0 335  3.54000  3.570000 33.90273  0.000000  1 #> Merc 230      22.80000   4 140.8  95  3.92000 -4.541341 22.90000 -8.556805  0 #> Merc 450SE    54.17757   8 275.8 180  3.07000  4.070000 17.40000  0.000000  0 #> Volvo 142E    21.40000   4 121.0 109  4.11000  2.780000 18.60000  1.000000  1 #>                    gear      carb   scores #> Duster 360    3.0000000   4.00000 29.58581 #> Maserati Bora 0.9829575   8.00000 27.95683 #> Merc 230      4.0000000   2.00000 27.30969 #> Merc 450SE    3.0000000   3.00000 26.99406 #> Volvo 142E    4.0000000 -12.91235 25.39721 multiOutliers(mtcarsOutliers, method=\"LoF\", minPts=5) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: LoF #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 7 9 10 11 12 19 20 29 31 32 #> Outlier Score: 3.146901 4.646142 3.401508 1.759811 2.00213 2.543073 1.915247 1.761172 2.28657 4.403093 1.772691 #> Message:  Outliers detected #> Option 1 : minPts = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp      hp     drat        wt     qsec #> Duster 360        14.30000  8.000000 360.0 245.000 18.14468  3.570000 15.84000 #> Maserati Bora     15.00000  8.000000 301.0 335.000  3.54000  3.570000 33.90273 #> Merc 230          22.80000  4.000000 140.8  95.000  3.92000 -4.541341 22.90000 #> Hornet Sportabout 18.70000 -4.137792 360.0 446.914  3.15000  3.440000 17.02000 #> Merc 450SE        54.17757  8.000000 275.8 180.000  3.07000  4.070000 17.40000 #>                          vs am      gear carb   scores #> Duster 360         0.000000  0 3.0000000    4 4.646142 #> Maserati Bora      0.000000  1 0.9829575    8 4.403093 #> Merc 230          -8.556805  0 4.0000000    2 3.401508 #> Hornet Sportabout  0.000000  0 3.0000000    2 3.146901 #> Merc 450SE         0.000000  0 3.0000000    3 2.543073 multiOutliers(mtcarsOutliers, method=\"kNN\", k=5, threshold=.95) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: kNN #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 11 19 #> Outlier Score: 547.8248 393.1049 #> Message:  Outliers detected #> Option 1 : k = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl      disp        hp     drat    wt #> Merc 280C         17.80000  6.000000 -459.2495  123.0000 3.920000 3.440 #> Honda Civic       30.40000  4.000000  783.2571   52.0000 4.930000 1.615 #> Merc 280          44.30673  6.000000  167.6000 -238.7728 4.560312 3.440 #> Hornet Sportabout 18.70000 -4.137792  360.0000  446.9140 3.150000 3.440 #> Maserati Bora     15.00000  8.000000  301.0000  335.0000 3.540000 3.570 #>                       qsec vs am      gear carb   scores #> Merc 280C         18.90000  1  0 4.0000000    4 547.8248 #> Honda Civic       18.52000  1  1 4.0000000    2 393.1049 #> Merc 280          18.30000  1  0 4.0000000    4 318.1242 #> Hornet Sportabout 17.02000  0  0 3.0000000    2 189.8207 #> Maserati Bora     33.90273  0  1 0.9829575    8 117.9942 multiOutliers(mtcarsOutliers, method=\"iForest\", ntrees = 50) #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: iForest #> Dataset: mtcarsOutliers #> Variables: mpg cyl disp hp drat wt qsec vs am gear carb scores #> Row: 5 9 10 20 31 #> Outlier Score: 0.6098171 0.5689141 0.5168466 0.4768288 0.4669088 #> Message:  Outliers detected #> Option 1 : ntrees = 50 #> Option 2 : n = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>                        mpg       cyl  disp        hp     drat        wt #> Merc 230          22.80000  4.000000 140.8   95.0000 3.920000 -4.541341 #> Maserati Bora     15.00000  8.000000 301.0  335.0000 3.540000  3.570000 #> Toyota Corolla    33.90000  4.000000  71.1   65.0000 4.220000  1.835000 #> Merc 280          44.30673  6.000000 167.6 -238.7728 4.560312  3.440000 #> Hornet Sportabout 18.70000 -4.137792 360.0  446.9140 3.150000  3.440000 #>                       qsec        vs am      gear      carb    scores #> Merc 230          22.90000 -8.556805  0 4.0000000  2.000000 0.6098171 #> Maserati Bora     33.90273  0.000000  1 0.9829575  8.000000 0.5689141 #> Toyota Corolla    19.90000  6.993352  1 4.0000000 -7.344032 0.5168466 #> Merc 280          18.30000  1.000000  0 4.0000000  4.000000 0.4768288 #> Hornet Sportabout 17.02000  0.000000  0 3.0000000  2.000000 0.4669088"},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.multiOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting Multivariate Outlier Detection — plot.multiOutliers","title":"Plotting Multivariate Outlier Detection — plot.multiOutliers","text":"Plots identified multivariate outliers using either kNN, iForest, mahalanobis, LoF","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.multiOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting Multivariate Outlier Detection — plot.multiOutliers","text":"","code":"# S3 method for class 'multiOutliers' plot(x, ...)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.multiOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting Multivariate Outlier Detection — plot.multiOutliers","text":"x results multivariate outlier detection function (e.g., kNN, iForest, mahalanobis, LoF)","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.multiOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting Multivariate Outlier Detection — plot.multiOutliers","text":"formatted plot results multivariate outlier detection. Row indices x-axis ou","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.multiOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting Multivariate Outlier Detection — plot.multiOutliers","text":"","code":"results <- multiOutliers(irisOutliers, method=\"iForest\") plot(results) #> Loading required package: ggplot2 #> Loading required package: grid   results <- multiOutliers(irisOutliers, method = \"kNN\") plot(results)   results <- multiOutliers(irisOutliers, method = \"LoF\") plot(results)   results <- multiOutliers(irisOutliers, method = \"mahalanobis\") plot(results)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.univOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting Univariate Outlier Detection — plot.univOutliers","title":"Plotting Univariate Outlier Detection — plot.univOutliers","text":"Creates visualizations univariate outlier detection using method-specific plot styles.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.univOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting Univariate Outlier Detection — plot.univOutliers","text":"","code":"# S3 method for class 'univOutliers' plot(outlier_results)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.univOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting Univariate Outlier Detection — plot.univOutliers","text":"outlier_results list containing results univariate outlier detection function (e.g., univOutliers).","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.univOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting Univariate Outlier Detection — plot.univOutliers","text":"plot object specific outlier detection method used (boxplot, MAD, Grubbs' test).","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/plot.univOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting Univariate Outlier Detection — plot.univOutliers","text":"","code":"object <- univOutliers(data = mtcars, x = \"carb\", method = \"mad\") #plot(object)  object2 <- univOutliers(data = mtcars, x = \"wt\", method = \"boxplot\") #plot(object2)  object3 <- univOutliers(data = mtcars, x = \"carb\", method = \"grubbs\") #> Warning: Data is not normally distributed. Grubbs' test may not be appropriate. #plot(object3)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.multiOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing Multivariate outlier detection — print.multiOutliers","title":"Printing Multivariate outlier detection — print.multiOutliers","text":"Prints identified multivariate outliers","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.multiOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing Multivariate outlier detection — print.multiOutliers","text":"","code":"# S3 method for class 'multiOutliers' print(x, ...)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.multiOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing Multivariate outlier detection — print.multiOutliers","text":"x results \"multiOutliers\" function","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.multiOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing Multivariate outlier detection — print.multiOutliers","text":"formatted print results \"multiOutliers\" function","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.multiOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing Multivariate outlier detection — print.multiOutliers","text":"","code":"#iForest results <- multiOutliers(irisOutliers, method = \"iForest\") results #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: iForest #> Dataset: irisOutliers #> Variables: Sepal.Length Sepal.Width Petal.Length Petal.Width Species scores #> Row: 30 111 112 130 134 #> Outlier Score: 0.665758 0.6534289 0.6319916 0.594985 0.5916989 #> Message:  Outliers detected #> Option 1 : ntrees = 100 #> Option 2 : n = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species    scores #> 112    -5.041526    7.131942      5.30000    1.900000 virginica 0.6657580 #> 111    -2.897649    3.200000     15.39435    2.000000 virginica 0.6534289 #> 30      4.700000    3.200000      1.60000    5.593282    setosa 0.6319916 #> 134     6.300000   -5.515252      5.10000    1.500000 virginica 0.5949850 #> 130     7.200000    3.000000      5.80000   -1.069324 virginica 0.5916989  #LoF results <- multiOutliers(irisOutliers, method = \"LoF\") results #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: LoF #> Dataset: irisOutliers #> Variables: Sepal.Length Sepal.Width Petal.Length Petal.Width Species scores #> Row: 4 11 20 24 27 30 33 37 42 44 45 47 56 60 64 73 75 77 78 84 99 104 105 107 111 112 130 134 138 141 #> Outlier Score: 2.290435 7.836175 5.326338 1.719472 7.643855 18.77654 1.690833 2.314559 1.962892 1.844472 6.450114 10.00998 6.894673 9.042709 6.779096 3.101874 2.939113 9.120049 3.301206 2.775807 2.960792 3.707248 4.397371 1.521473 6.528664 8.473346 5.857273 7.119732 3.219712 3.336054 #> Message:  Outliers detected #> Option 1 : minPts = 10 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species    scores #> 30      4.700000    3.200000     1.600000    5.593282     setosa 18.776542 #> 47     13.284890    3.800000     1.600000    0.200000     setosa 10.009984 #> 77      6.800000    2.800000    -8.799906    1.400000 versicolor  9.120049 #> 60      5.200000    2.700000    18.737610    1.400000 versicolor  9.042709 #> 112    -5.041526    7.131942     5.300000    1.900000  virginica  8.473346  #kNN results <- multiOutliers(irisOutliers, method = \"kNN\") results #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: kNN #> Dataset: irisOutliers #> Variables: Sepal.Length Sepal.Width Petal.Length Petal.Width scores #> Row: 27 47 60 64 77 104 111 112 134 #> Outlier Score: 5.530942 7.280213 8.092378 5.331189 10.22672 4.959793 9.058028 9.24345 7.133188 #> Message:  Outliers detected #> Option 1 : k = 5 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>     Sepal.Length Sepal.Width Petal.Length Petal.Width    scores #> 77      6.800000    2.800000    -8.799906         1.4 10.226716 #> 112    -5.041526    7.131942     5.300000         1.9  9.243450 #> 111    -2.897649    3.200000    15.394346         2.0  9.058028 #> 60      5.200000    2.700000    18.737610         1.4  8.092378 #> 47     13.284890    3.800000     1.600000         0.2  7.280213  #Mahalanobis results <- multiOutliers(irisOutliers, method = \"mahalanobis\") results #>  #> ── Summary Information ───────────────────────────────────────────────────────── #>  #> Method: mahalanobis #> Dataset: irisOutliers #> Variables: Sepal.Length Sepal.Width Petal.Length Petal.Width scores #> Row: 11 20 27 30 45 47 56 60 64 77 104 105 111 112 130 134 138 #> Outlier Score: 8.155109 14.47815 37.83847 41.81264 11.15972 26.21562 12.26051 35.42845 12.70324 29.3269 13.30429 10.38707 42.30386 50.29761 14.22322 53.01116 8.450311 #> Message:  Outliers detected #> Option 1 : alpha = 0.1 #>  #> ── Dataset Information ───────────────────────────────────────────────────────── #>  #> Five Highest Outliers of Data Used: #>     Sepal.Length Sepal.Width Petal.Length Petal.Width   scores #> 134     6.300000   -5.515252      5.10000    1.500000 53.01116 #> 112    -5.041526    7.131942      5.30000    1.900000 50.29761 #> 111    -2.897649    3.200000     15.39435    2.000000 42.30386 #> 30      4.700000    3.200000      1.60000    5.593282 41.81264 #> 27      5.000000   10.344843      1.60000    0.400000 37.83847"},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.univOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing Univariate Outlier Detection Results — print.univOutliers","title":"Printing Univariate Outlier Detection Results — print.univOutliers","text":"Prints identified univariate outliers using specified method (boxplot, MAD, Grubbs' test).","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.univOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing Univariate Outlier Detection Results — print.univOutliers","text":"","code":"# S3 method for class 'univOutliers' print(x, ...)"},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.univOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing Univariate Outlier Detection Results — print.univOutliers","text":"x results univariate outlier detection function (e.g., output univOutliers).","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.univOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing Univariate Outlier Detection Results — print.univOutliers","text":"formatted print outlier results, including detected outliers, row numbers, method used.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/print.univOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing Univariate Outlier Detection Results — print.univOutliers","text":"","code":"object <- univOutliers(data = mtcars, x = \"carb\", method = \"mad\") print(object) #> Loading required package: cli #> Loading required package: knitr #>  #> ── Method Chosen: mad ────────────────────────────────────────────────────────── #> Variable: carb #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      31              8         object2 <- univOutliers(data = mtcars, x = \"wt\", method = \"boxplot\") print(object2) #>  #> ── Method Chosen: boxplot ────────────────────────────────────────────────────── #> Variable: wt #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      16            5.424      #>      17            5.345       object3 <- univOutliers(data = mtcars, x = \"carb\", method = \"grubbs\") #> Warning: Data is not normally distributed. Grubbs' test may not be appropriate. print(object3) #>  #> ── Method Chosen: grubbs ─────────────────────────────────────────────────────── #> Variable: carb #>  #> Outliers Detected for: #>  #>  #>  Row Number    Outlier Value  #> ------------  --------------- #>      31              8"},{"path":"https://github.com/chenning2011/qacOutliers/reference/univOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate Outlier Detection — univOutliers","title":"Univariate Outlier Detection — univOutliers","text":"Detects univariate outliers using boxplot, MAD, Grubbs' test.","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/univOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate Outlier Detection — univOutliers","text":"","code":"univOutliers(data, x = NULL, method = \"boxplot\")"},{"path":"https://github.com/chenning2011/qacOutliers/reference/univOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate Outlier Detection — univOutliers","text":"data data frame containing variable(s) analyzed x character, specifies column(s) assess outliers. NULL, numeric columns used method character, method used outlier detection: \"boxplot\", \"mad\", \"grubbs\" (default \"boxplot\")","code":""},{"path":"https://github.com/chenning2011/qacOutliers/reference/univOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate Outlier Detection — univOutliers","text":"list detected outliers, indices, method used, original dataset","code":""},{"path":[]}]
