---
title: "qacOutliers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{qacOutliers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning = F, message = F}
library(qacOutliers)
```

### What are outliers? 
Outliers--also known as anamolies, abnormalities, discordants, or deviants--are observations that differ significantly from the rest of the observations in a dataset. There are many different reasons that outliers can exist in a dataset, including natural variation in a population and measurement error.

Natural variations can be seen in many different ways. For example, if you have a dataset of people's salaries that includes a random sample of all people, there could be observations from billionaires, who have a much larger salary than the average person, which would distort the data. 

Measurement or experimental errors can occur during the data collection process. For example, if an experiment was recording people's heights, and the measurement was accidentally entered as 52' instead of 5'2", that value would be an outlier. This isn't because the person is abnormally tall, but because their height was recorded incorrectly. 

### How can you detect outliers? How can I use this package to detect outliers?

Detecting outliers, like many techniques in data science, is more of an art than a science. Because there are so many different reasons that outliers exist, there are many different ways to detect them. This package includes seven commonly used methods for [univariate](Univariate.html) and [multivariate](Multivariate.html) outlier detection. See the linked pages above for more information about those specific methods. 

Each of these seven methods have distinct methods for identifying and calculating outliers, ranging from visualizing data to standardizing it and calculating scores for each variable to identify which observations are mathematically furthest away from the rest of the data. Although each of these methods return observations that have been classified as outliers by their respective functions, it's important to always look at the underlying data to understand why they are being picked out as outliers, if they truly are outliers, and why they might have the values that they have. 

### Why should we detect outliers?

Because there are so many reasons for there to be outliers in a dataset, it's always important to take a moment to understand if there are any potential outliers within your data. Any techniques that utilize means are heavily affected by the presence of outliers, so it's extra important to look for outliers before taking the mean of any variables in a dataset. 

Additionally, as outliers can be generated through measurement errors, they provide context into any issues that may arise during data collection. These findings are especially helpful when you are collecting your own data. If you are aware of any issues with data collection within your datasets, these techniques will help you identify points where mistakes may have been made. 

### What should you do with outliers once you detect them? 

This depends on many factors, including the cause of the outlier (if known), the magnitude of the outlier, and whether you believe the detected outliers are truly outliers. Because there are so many reasons that outliers exist, and because some detected outliers may not really be outliers, this package allows you to decide how you want to proceed. 

Once you run one of these functions, you can extract the row numbers of detected outliers and carefully inspect your data to decide what you want to do with the detected outliers. Here is an example of multivariate outliers detected with the [LoF](Multivariate.html#local-outlier-factor-lof) method, using [mtcarsOutliers](https://chenning2011.github.io/qacOutliers/reference/mtcarsOutliers.html), a dataset included in this package. 

```{r}
results <- multiOutliers(mtcarsOutliers, method = "lof")
results
```

The LoF function detected nine outliers within this dataset. From this output, you can identify which rows these outliers are in, and extract them to inspect these observations. 

```{r}
index <- results$Row
subset <- mtcarsOutliers[index,]
subset
```

Looking at this dataset, we can easily see that a lot of the detected outliers are likely true outliers. All of these values should be positive, so any negative values are likely the result of measurement error and can be removed (which takes out the Hornet Sportabout, the Merc 280C, the Merc 280, the Merc 230, the Toyota Corrolla, and the Volvo 142E). Some of the other values look much larger than they should be, which will require a closer look at the distributions of values for those variables. Once you have better understood the underlying data, you can decide whether to remove these values from your data before conducting further analysis. 

Here is an example of how to remove the observations from your dataset. This example also shows you how to add the score value from the multiOutliers function as a variable in your dataset. 

```{r}
#adding the scores from the multiOutliers function 
mtcarsOutliers$results <- results$Data$scores

#identfying all rows with outliers
index <- results$Row

#creating a new dataset with no outliers
noOutliers <- mtcarsOutliers[-index,]
noOutliers
```




